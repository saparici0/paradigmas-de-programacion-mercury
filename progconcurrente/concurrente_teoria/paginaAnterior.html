<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
  <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css"
    integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

  <script src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></script>
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  <style>
    li a {
      display: block;
      color: white;
      text-align: center;
      padding: 16px;
      text-decoration: none;
    }

    li a:hover {
      background-color: #111111;
    }

    blockquote {
      background: #f9f9f9;
      border-left: 10px solid #ccc;
      margin: 1.5em 10px;
      padding: 0.5em 10px;
      quotes: "\201C""\201D""\2018""\2019";
    }

    blockquote:before {
      color: #ccc;
      content: open-quote;
      font-size: 4em;
      line-height: 0.1em;
      margin-right: 0.25em;
      vertical-align: -0.4em;
    }

    blockquote p {
      display: inline;
    }
  </style>
  <title>Programación concurrente</title>
  <nav id="main-nav" class="navbar navbar-expand-xl navbar-dark bg-dark sticky-top">
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto" data-toggle="collapse" data-target="#navbarSupportedContent.show">
        <li class="nav-item"><a class="nav-link" href="#historia">Historia</a></li>
        <li class="nav-item"><a class="nav-link" href="#filosofía">Filosofia</a></li>
        <li class="nav-item"><a class="nav-link" href="#definición">Definición</a></li>
        <li class="nav-item"><a class="nav-link" href="#CvP">Concurrencia VS Paralelismo</a></li>
        <li class="nav-item"><a class="nav-link" href="#conceptos">Conceptos</a></li>
        <li class="nav-item"><a class="nav-link" href="#ejecucion-concurrente">Ejecución concurrente</a></li>
        <li class="nav-item"><a class="nav-link" href="#aplicaciones">Aplicaciones del paradigma</a></li>
        <li class="nav-item"><a class="nav-link" href="#ventajas">Ventajas</a></li>
        <li class="nav-item"><a class="nav-link" href="#desventajas">Desventajas</a></li>
        <li class="nav-item"><a class="nav-link" href="#lenguajes">Lenguajes</a></li>
        <li class="nav-item"><a class="nav-link" href="#ejemplos">Lenguajes ejemplos</a></li>
        <li class="nav-item"><a class="nav-link" href="#referencias">Referencias</a></li>
        <li class="nav-item"><a class="nav-link" href="#Integrantes">Integrantes</a></li>
        <li class="nav-item"><a class="nav-link" href="quiz/index.html">Test</a></li>
      </ul>
    </div>
  </nav>
</head>

<body style="position: relative;" data-spy="scroll" data-target="#main-nav" data-offset="0">

  <header>
    <div class="inner">
      <br />
      <h1>Programación concurrente</h1>
    </div>
  </header>

  <div id="content-wrapper">
    <div class="inner clearfix">
      <section id="main-content">

        <div class="text-justify">
          <div id="historia">
            <br> <br>
            <h1>
              <a class="anchor" href="#historia%C3%ADa" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Historia
            </h1>
            <p>A menudo se asume que Dijkstra instigó el estudio de la programación concurrente en su ahora clásico
              artículo "Procesos secuenciales de cooperación", publicado en 1967. Ciertamente, en ese artículo vemos la
              introducción de algunos problemas ahora bien conocidos como "The Dining Philosophers "," The Sleeping
              Barber "y" The Dutch Flag Problem ", y quizás lo más importante, el problema de la sección crítica y su
              solución utilizando semáforos. Este artículo fue, de hecho, el primero en tener una visión de alto nivel
              de la programación concurrente. Como nota aparte, es interesante observar que el mismo artículo introduce
              la noción de interbloqueo y presenta un algoritmo que puede detectar la posible presencia de bloqueos.
              Sin embargo, a principios de la década de 1960, primero se presentó Conway y luego Dennis y Van Horn. La
              idea de múltiples hilos de control se introdujo en este momento, y es interesante observar que algunos de
              los problemas de acceso a recursos compartidos, como la memoria, también se abordaron en ese momento. Al
              igual que en el desarrollo de lenguajes de programación [secuencial] de alto nivel, los investigadores se
              dieron cuenta de los problemas asociados con el uso de estas construcciones de bajo nivel, principalmente
              en el área de tratar de escribir programas de manera correcta y rápida. y como resultado se inventaron
              construcciones de más alto nivel y más restrictivas. Por lo tanto, ahora vemos una plétora de diferentes
              técnicas para proporcionar programación concurrente controlada, muchas de las cuales examinaremos con
              mayor detalle en los últimos capítulos de este libro</p>
            <p>
              La computación concurrente se desarrolló a partir de trabajos anteriores sobre ferrocarriles y telegrafía,
              del siglo XIX y principios del XX, y algunos términos datan de este período, como semáforos. Estos
              surgieron para abordar la cuestión de cómo manejar múltiples trenes en el mismo sistema ferroviario
              (evitando colisiones y maximizando la eficiencia) y cómo manejar múltiples transmisiones a través de
              un conjunto determinado de cables (mejorando la eficiencia), como a través de multiplexación por división
              de tiempo (década de 1870) ).
            </p>
        
            <p>
              Es fascinante observar la evolución de la programación concurrente a lo largo del tiempo y cómo sus
              fundamentos se pueden rastrear hasta problemas prácticos en sectores como ferrocarriles y telegrafía.
              Además de los hitos mencionados, hay algunos aspectos y desarrollos adicionales a considerar:
            </p>
        
            <ol>
              <li>
                <b>Lenguajes Concurrentes:</b> A medida que la programación concurrente evolucionó, surgieron lenguajes de
                programación específicos para manejar la concurrencia de manera más efectiva. Ejemplos notables incluyen
                Erlang, desarrollado por Ericsson para sistemas de telecomunicaciones concurrentes, y Ada, que también
                incluye características para la concurrencia.
              </li>
        
              <li>
                <b>Modelos de Concurrencia:</b> A lo largo del tiempo, se han propuesto varios modelos de concurrencia para
                abordar
                los desafíos de la programación concurrente. Ejemplos incluyen el modelo de actores, el modelo CSP
                (Comunicating Sequential Processes) de Tony Hoare, y el modelo de memoria transaccional.
              </li>
        
              <li>
                <b>Programación Concurrente en la Era de los Multiprocesadores:</b> Con el aumento de los sistemas
                multiprocesador
                y la computación en paralelo, la programación concurrente se ha vuelto aún más crucial. Las tecnologías como
                OpenMP y MPI permiten la programación concurrente en entornos de multiprocesadores y clústeres.
              </li>
        
              <li>
                <b>Concurrencia en el Desarrollo de Software Moderno:</b> En el contexto actual, donde la concurrencia y la
                paralelización son esenciales para aprovechar al máximo la potencia de hardware moderno, se han desarrollado
                marcos y bibliotecas para facilitar la programación concurrente. Ejemplos incluyen el uso de hilos en
                lenguajes como Java y Python, así como bibliotecas como concurrent.futures y asyncio.
              </li>
        
              <li>
                <b>Problemas Emergentes en Concurrencia:</b> A medida que las aplicaciones se vuelven más complejas, surgen
                nuevos
                desafíos en la programación concurrente, como la gestión de la concurrencia en entornos distribuidos, la
                sincronización de datos compartidos y la resolución de problemas de rendimiento y escalabilidad.
              </li>
            </ol>
          </div>

          <div id="filosofía">
            <br> <br>
            <h1>
              <a class="anchor" href="#filosof%C3%ADa" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Filosofía
            </h1>

            <p>Es la división de un problema en subproblemas que se solucionan de forma individual, para crear un
              programa o aplicación que no se vea afectada en tiempo real.</br>
              Las dificultades de la concurrencia:
            </p>

            <ul>
              <li>¿Cómo mantener el acceso a recursos compartidos correcto y eficiente?</li>
              <li>¿Cómo permitir a los programadores razonar sobre un programa concurrente?</li>
              <li>¿Cómo modelar la composición de tareas concurrentes?</li>
              <li>¿Cuál es la abstracción más ergonómica para escribir programas concurrentes?</li>
            </ul>

            <h3>Modelos de concurrencia</h3>

            <p>La solución general en el mundo de la computación viene a apoyarnos en la solución a estos problemas: la
              abstracción.</p>

            <img src="images/UnidadBasicaDeConcurrencia.png" style="margin-left: 30px; margin-bottom: 20px">

          </div>

          <div id="definición">
            <br> <br>

            <h1>
              <a class="anchor" href="#definici%C3%B3n" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Definición
            </h1>

            <p>Hace referencia a las técnicas de programación que son utilizadas para expresar la concurrencia entre
              tareas y solución de los problemas de comunicación y sincronización entre procesos.
              La programación concurrente es la ejecución simultánea de múltiples tareas interactivamente. Estas tareas
              pueden ser un conjunto de procesos o hilos de ejecución
              creados por un único programa. Las tareas se pueden ejecutar en una sola CPU (multiprogramación), en
              varios procesadores, o en una red de computadores distribuidos. </p><br>
            <!--
<img src="https://s3.postimg.org/435ixtj2r/definicion.jpg" style="margin-left: 30px"> -->

            <img src="images/concurrentProcess.png" style="margin-left: 30px; margin-bottom: 20px">
            <p><br>
              La programación concurrente no es más que la forma en la cual podemos
              resolver ciertas problemáticas de forma concurrente, es decir, ejecutando múltiples tareas a la misma vez
              y no de forma secuencial.  En un programa concurrente las tareas puede continuar sin la necesidad que otras
              comiencen o finalicen. <br>
              Si bien es cierto que la programación concurrente acarrea ciertos problemas, principalmente al momento de
              compartir información entre tareas, también es cierto que si se implementa de forma correcta, podremos, en
              casos puntuales, mejorar significativamente el performance de nuestras aplicaciones.
            </p>
          </div>
          <div id="CvP">
            <br> <br>
            <h1>
              <a class="anchor" href="#CvP%C3%ADa" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Concurrencia VS Paralelismo
            </h1>
            <p>
              Este puede llegar a ser uno de los puntos que más interés puede llegar a causar en los programadores
              y con justa razón, ya que son términos que pueden llegar a confundirse fácilmente, es por ello que es
              necesario aprender a diferenciarlos.
            </p>
            <p>
              <strong>La concurrencia es una forma de estructurar una solución que puede ser paralelizable (Aunque no
                siempre) </strong>
            </p>
            <section id="diff">

              <div class="row text-justify">
                <div class="col-md-6">
                  <h3 class="text-center">Concurrencia</h3>
                  <ul>
                    <li>
                      Soporta dos o más acciones en progreso
                    </li>
                    <li>
                      Procesos que se ejecutan de manera independiente
                    </li>
                    <li>
                      Lidiar con muchas cosas al tiempo
                    </li>
                    <li>
                      Sobre la estructura
                    </li>
                  </ul>
                </div>
                <div class="col-md-6">
                  <h3 class="text-center">Paralelismo</h3>
                  <ul>
                    <li>
                      Soporta dos o más acciones ejecutándose simultáneamente
                    </li>
                    <li>
                      Procesos que se ejecutan Simultáneamente (tal vez relacionados)
                    </li>
                    <li>
                      Hacer muchas cosas al tiempo
                    </li>
                    <li>
                      Sobre la ejecución
                    </li>
                  </ul>

                </div>
              </div>

            <h2>Como diferenciarlas?</h2>
            La concurrencia y el paralelismo han sido extensamente discutidos, pero al momento de definirlos, varios
            autores salen con su propia definición y esta variedad no hacen tan fácil la tarea de entender.
            En términos sencillos, se puede explicar así:
            <blockquote>
              Un programa es concurrente si puede soportar dos o más acciones<strong> en progreso.</strong><br><br>
              Un programa es paralelo si puede soportar dos o más acciones <strong>ejecutándose
                simultáneamente.</strong>"
            </blockquote>

            <img src="images/diferent.PNG" style="margin-left: 30px  " height="400" width="1500">

            La palabra clave es <strong>en progreso</strong>.<br><br>
            Un programa es concurrente por que maneja varias tareas al mismo tiempo, define acciones que
            <strong>pueden</strong> ser ejecutadas al mismo tiempo.<br>
            Y para que un programa sea paralelo, no solo debe ser concurrente, sino que tambien debe estar diseñado para
            correr en un medio con hardware paralelo (GPU's, procesadores multi-core, etc).<br><br>
            Puede ser visto como que la concurrencia es la propiedad de un programa, mientras que el paralelismo es la
            forma en la que se ejecuta un programa concurrente.<br><br>

            Para entender esta diferencia, también podemos usar una analogía de una cafetería y un barista, y en la que hay 
            dos tareas disponibles: tomar pedidos y preparar café.<br><br>

            Supongamos que tenemos la cafetería con un solo barista. En este escenario, 
            el barista toma pedidos y prepara café para los clientes que llegan. Mientras espera que el café se prepare, 
            en lugar de estar inactivo, puede atender a otro cliente y tomar su pedido. Aunque cada tarea individual (tomar 
            un pedido o preparar café) no ocurre al mismo tiempo, la cafetería está manejando múltiples flujos de trabajo 
            de manera concurrente a través del barista. Es como si el barista estuviera alternando entre tomar pedidos 
            y preparar bebidas, gestionando varias tareas de manera eficiente aunque no todas estén en progreso de forma 
            simultánea. A esto se le conoce como <strong>concurrencia</strong>. <br><br>

            Ahora, supongamos que tenemos una cafetería con varios baristas, cada uno con su propia área de trabajo y su 
            propia máquina de café. En esta situación, cada barista puede atender a un cliente de manera 
            independiente. Pueden tomar pedidos y preparar bebidas de forma simultánea. La clave aquí es que las acciones 
            de cada barista están ocurriendo verdaderamente al mismo tiempo, aprovechando los recursos individuales de 
            cada uno. Este escenario refleja el <strong>paralelismo</strong>, donde múltiples tareas se ejecutan 
            simultáneamente gracias a la disponibilidad de recursos independientes (múltiples baristas). Cada barista es 
            como un núcleo de procesador en un sistema que permite la verdadera simultaneidad en la ejecución de 
            tareas. <br><br>

            <h2>
              <a id="relacion" class="anchor" href="#relacion" aria-hidden="true">
                <span aria-hidden="true" class="octicon octicon-link"></span></a>Relación
            </h2>

            <p>Múltiples procesos pueden ser ejecutados al mismo tiempo. En otras palabras, la programación concurrente
              se comporta igual que la paralela cuando tenemos un sistema multiprocesador en el cual cada unidad de
              procesamiento ejecuta un proceso o hilo. En la imagen inferior podemos ver que la unidad de
              procesamiento 2 y 3 se comportan igual.</p><br>

            <h2><a id="relacion" class="anchor" href="#relacion" aria-hidden="true"></a>Ejemplo de concurrencia:</h2>

            <p>Imagina una aplicación de descarga de música, en la cual puedes descargar un número determinado de
              canciones al mismo tiempo,
              cada canción es independiente de la otra, por lo que la velocidad y el tiempo que tarde en descargarse
              cada una no afectara al
              resto de canciones. Esto lo podemos ver como un proceso concurrente, ya que cada descarga es un proceso
              totalmente
              independiente del resto.</p><br>

              <img src="images/ejemplo_concurrente.png" style="display: block; margin-right: auto; margin-left: auto;" height="347" width="471" class="center"><br><br>

            <p>Observa la imagen, cada descarga se procesa de forma separada, y al final a una descarga no le importa el
            estado de las demás. Ya que cada descarga es una tarea completamente diferente.</p><br>


            <h2><a id="relacion" class="anchor" href="#relacion" aria-hidden="true"></a>Ejemplo de paralelismo:</h2>

            <p>
              Imagina la clásica página de viajes, donde nos ayudan a buscar el vuelo más barato o las mejores
              promociones,
              para hacer esto, la página debe de buscar al momento en cada aerolínea el vuelo más barato, con menos
              conexiones, etc.
              Para esto puedo hacerlo de dos formas, buscar secuencialmente en cada aerolínea las mejores promociones
               (muy tardado)
              o utilizar el paralelismo para buscar al mismo tiempo las mejores promociones en todas las aerolíneas.
            </p><br>

            <img src="images/ejemplo_paralelismo.png" style="display: block; margin-right: auto; margin-left: auto;" height="412" width="471"><br><br>

            <p>Observemos en la imagen como el proceso parte de una entrada inicial (inputs) los cuales definen
              las características del vuelo a buscar, luego se utiliza la concurrencia para buscar en las cuatro
              aerolíneas al mismo tiempo. Veamos que en este proceso es indispensable que las 4 búsquedas terminen
              para poder arrojar un resultado. Podemos ver claramente la relación entre los 4 procesos, ya que el
              resultado
              de uno puedo afectar al proceso final.
              <br><br>
              Observemos también que una vez que los cuatro procesos terminan, hay un subproceso adicional
              encargado de unir los resultados y arrojar un resultado final.
            </p><br>

            <h2>
              <a id="relacion" class="anchor" href="#relacion" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Proceso o Hilo ?
            </h2>
            <p>Primero, los procesos son más pesados de crear y, por lo tanto, utilizan más capacidades de computadora
              que los hilos. Esto permite entonces de hacer tareas más pesadas.<br /><br />

              En segundo lugar, los procesos son totalmente independientes entre ellos. No comparten ningún dato entre
              ellos; Mientras que, los hilos pueden compartir información fácilmente.<br /><br />

              Desafortunadamente, esto crea un problema: si dos hilos trabajan con los mismos datos, se puede crear
              errores como, por ejemplo, el valor cambia sin entender por qué. De hecho, cuando se realizan dos tareas
              al mismo tiempo, si modificamos los datos en un hilo y hacemos lo mismo en la otra, será imposible
              predecir qué hilo modificarán primero la variable.<br />
              Para esto, hay un sistema para "bloquear" los datos en un hilo. Una vez que este hilo desbloqueará los
              datos, el otro hilo recibirá una señal de que puede modificarlo.<br />
              Para resumir, cuando se trabaja en los mismos datos con dos subprocesos diferentes, es necesario bloquear
              los datos en un hilo en el momento de modificarlo, y luego desbloquearlo.</p><br />
            <p><img src="images/process_hilo.png" style="display: block; margin-right: auto; margin-left: auto;"></p><br /><br /><br />

            <p><img src="http://s32.postimg.org/s503ixn05/paralellismo.jpg" alt=""></p>

            <p>Hay que aclarar la concurrencia no solo es paralelismo, ya que, cuando hay más procesos o hilos el
              scheduler del sistema operativo interviene y divide la ejecución de los procesos, <strong>característica
                que la programación paralela NO tiene</strong> cada proceso tiene que ser ejecutado exclusivamente en
            una unidad de procesamiento. En la parte inferior podemos apreciar mejor la diferencia.</p><br>

            <p><img src="http://joearms.github.io/images/con_and_par.jpg" alt=""></p>
            <p><strong>Cuadro comparativo Procesos vs Hilos: </strong></p>
            <table class="table">
              <thead class="thead-dark">
                <tr>
                  <th scope="col">#</th>
                  <th scope="col">Procesos</th>
                  <th scope="col">Hilos</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <th scope="row">1</th>
                  <td>Son programas en ejecución.</td>
                  <td>Son segmentos de procesos.</td>
                </tr>
                <tr>
                  <th scope="row">2</th>
                  <td>Tardan más tiempo en terminar.</td>
                  <td>Tardan menos tiempo en terminar.</td>
                </tr>
                <tr>
                  <th scope="row">3</th>
                  <td>Toma más tiempo crearlos.</td>
                  <td>Toma menos tiempo crearlos.</td>
                </tr>
                <tr>
                  <th scope="row">4</th>
                  <td>Toma más tiempo hacer el cambio de contexto.</td>
                  <td>Toma menos tiempo hacer el cambio de contexto.</td>
                </tr>
                <tr>
                  <th scope="row">5</th>
                  <td>Son menos eficientes en términos de comunicación.</td>
                  <td>Son meás eficientes en términos de comunicación.</td>
                </tr>
                <tr>
                  <th scope="row">6</th>
                  <td>Consumen más recursos.</td>
                  <td>Consumen menos recursos.</td>
                </tr>
                <tr>
                  <th scope="row">7</th>
                  <td>Son aislados.</td>
                  <td>Comparten memoria.</td>
                </tr>
                <tr>
                  <th scope="row">8</th>
                  <td>Son denominados "heavy weight process".</td>
                  <td>Son denominados "light weight process".</td>
                </tr>
                <tr>
                  <th scope="row">9</th>
                  <td>Los procesos tienen su propio PCB, Stack y espacio en memoria.</td>
                  <td>Los hilos tienen el PCB de sus padres, su propio Thread Control Block (TCB) y Stack y un
                    espacio de memoria compartido. </td>
                </tr>
              </tbody>
            </table>

            </section>
            <section id="ejemp">
              <div>
                <h3>Ejemplos Gophers</h3>
                
                <p>
                  Los Gophers son la mascota de Go (un roedor) los cuales se usaran para el siguiente ejemplo.<br>
                  Imagina que tenemos un Gopher que tiene que llevar una pila de libros a un incinerador, para esto,
                  usa un carro para llevar cierta cantidad de libros al incinerador y luego volver a la pila para reponer dicho carro.
                </p>
                <img src="images/Gopher1.png" style="margin-left: 30px; margin-bottom: 20px">

                <p>
                  Si agregamos otro Gopher al ejemplo este no podrá hacer nada porque las herramientas estarán ocupadas por su
                  compañero como se ve en la siguiente imagen.
                </p>
                <img src="images/Gopher2.png" style="margin-left: 30px; margin-bottom: 20px">

                <p>
                  Para este caso simple tenemos dos soluciones simples, una concurrente y la otra paralela.<br>
                  La solución concurrente es que se añada otro carro para que el segundo Gopher pueda trabajar, sin embargo
                  esto ocasiona que se necesite una sincronización entre los Gophers porque si los dos llegan al incinerador
                  al mismo tiempo uno tendrá que esperar al otro, provocando una pérdida de efectividad.
                </p>
                <img src="images/Gopher3.png" style="margin-left: 30px; margin-bottom: 20px">
                <p>
                  La solución paralela es duplicar todo, usando dos pilas de libros, dos carros y dos incineradores,
                  provocando que no se necesite gestionar la sincronización entre los Gophers y que ambos puedan trabajar todo el tiempo.
                </p>
                <img src="images/Gopher4.png" style="margin-left: 30px; margin-bottom: 20px">
                <p>
                  Para complicar el ejemplo ahora vamos a usar 4 Gophers. Usando una solución concurrente podemos gestionar a los 4 Gophers
                  para que hagan tareas diferentes y completamente independientes, el primero llena el carro con libros, el segundo lleva el
                  carro al incinerador, el tercero arroja los libros del carro al incinerador, y el cuarto regresa el carro a la pila de libros.
                </p>
                <img src="images/Gopher5.png" style="margin-left: 30px; margin-bottom: 20px">
                <p>
                  Como se dijo anteriormente una solución concurrente puede ser fácilmente paralelizadle, y en este ejemplo no es la excepción,
                  lo único que se necesita es duplicar todo y que todo se haga al tiempo.
                </p>
                <img src="images/Gopher6.png" style="margin-left: 30px; margin-bottom: 20px">
                
              </div>
            </section>
          </div>


          <div id="conceptos">
            <br><br>


            <h1>Conceptos</h1>
            <h2><a id="proceso" class="anchor" href="#proceso" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Proceso</h2>

            <p>Un proceso no solamente es el código de un programa, un proceso tiene un <strong>contador de
                programa</strong> el cual es un registro del computador que
              indica la dirección de la siguiente instrucción que será ejecutada por el proceso, <strong>Pila de
                proceso</strong> Esta contiene datos temporales
              tales como: Los parámetros de las funciones, direcciones de retorno, variables locales , … ,
              <strong>Sección de datos</strong> la cual contiene datos
              tales como las variables locales, Heap: Cúmulo de memoria que es la memoria que se asigna dinámicamente al
              proceso n tiempo de ejecución
            </p>

            <div class="center">
              <p><img
                  src="https://www.cs.uic.edu/%7Ejbell/CourseNotes/OperatingSystems/images/Chapter3/3_01_Process_Memory.jpg"
                  style="display: block; margin-right: auto; margin-left: auto;"></p><br>
            </div>

            <p><strong>Note</strong> que un programa por sí sólo no es un proceso, ya que este es una entidad pasiva que
              contiene una lista de instrucciones almacenadas en disco ( archivo ejecutable), mientras que un proceso es
              una entidad activa, el cual cumple todas las características descritas anteriormente.</p><br>

            <h3>Estados del proceso</h3>
            <p>
              Cuando un proceso es ejecutado este cambia de estados, los estados que todo proceso tiene por lo general
              son:</p>

            <ul>
              <li>
                <p><strong>Nuevo</strong>: El proceso se está creando.</p>
              </li>
              <li>
                <p><strong>Corriendo</strong>: Se están ejecutando las instrucciones.</p>
              </li>
              <li>
                <p><strong>Espera</strong>: El proceso está esperando que algún evento ocurra.</p>
              </li>
              <li>
                <p><strong>Preparado</strong>: El proceso está esperando ser asignado al procesador.</p>
              </li>
              <li>
                <p><strong>Terminado</strong>: El proceso a terminado la ejecución. </p>
              </li>
            </ul><br>

            <img
              src="https://www.cs.uic.edu/%7Ejbell/CourseNotes/OperatingSystems/images/Chapter3/3_02_ProcessState.jpg"
              style="display: block; margin-right: auto; margin-left: auto;"></p><br>
            </li>
            <h3>PCB ( Bloque de control de proceso )</h3>
            <p>
              Cada proceso se representa en el sistema operativo mediante el PCB, entre los elementos de información que
              este contiene se encuentran:</p>

            <ul>
              <li>
                <p><strong>Estado del proceso</strong>: New, ready, running, waiting, halted, ...</p>
              </li>
              <li>
                <p><strong>Contador del programa</strong>: </p>
              </li>
              <li>
                <p><strong>Registros de la CPU</strong>: Estos varían en cuanto a número y tipo dependiendo de la
                  arquitectura del procesador</p>
              </li>
              <li>
                <p><strong>Información de planificación de la CPU</strong>: Parametros de planificación como prioridad
                  de procesos, punteros a las colas de planificación ...</p>
              </li>
              <li>
                <p><strong>Información de gestión de memoria</strong>: Tablas de páginas , tablas de segmentos,
                  dependiendo los mecanismos de gestión del S.O</p>
              </li>
            </ul>

            <div class="center">
              <p><img src="https://www.cs.uic.edu/%7Ejbell/CourseNotes/OperatingSystems/images/Chapter3/3_03_PCB.jpg"
                  style="display: block; margin-right: auto; margin-left: auto;"></p>
            </div>

            <h2>
              <a id="hilo" class="anchor" href="#hilo" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Hilo
            </h2>

            <p>Se puede definir como una unidad básica de ejecución del Sistema Operativo para la utilización del CPU.
              Este es quien va al procesador y realiza todos los cálculos para que el programa se pueda ejecutar. Es
              necesario, ya que debe contar con al menos un hilo para que cualquier programa sea ejecutado.
              Cada hilo tiene: id de hilo, contador de programa, registros, stack.
              Dentro de las características que se encuentran se tiene que cada hilo tiene información del código de
              máquina que se va a ejecutar en el procesador, sus respectivos datos, el acceso a los archivos, el
              registro y su respectivo stack en donde se guarda toda la información necesaria del hilo como son las
              variables locales, variables de retorno o algo a lo que se acceda en tiempo de ejecución.
              Los hilos que pertenecen a un mismo proceso comparten: sección de código, sección de datos, entre otros
              recursos del sistema.
              El multithreading es la capacidad para poder proporcionar múltiples hilos de ejecución al mismo tiempo.
              Una aplicación por lo general es implementada como un proceso separado con muchos hilos de control.
              Dentro de las semejanzas de hilo y multihilo es que poseen un solo bloque de control de proceso (PCB) y un
              solo espacio de direcciones de proceso. Por el contrario, en las diferencias es que mientras un hilo tiene
              una pila para sus registros y stack, el multihilo tiene una pila para cada hilo con subbloques de control
              internos, incluyendo la pila de registros y sus respectivos stacks.
              Se dice que los hilos de ejecución que comparten recursos agregando estos recursos da como resultado el
              proceso.</p>
            <!--
<p><img src="https://s3.postimg.org/z6m2055rn/procesoshilos.jpg" style="margin-left: 30px"></p> -->


            <img src="images/hilo.PNG" style="margin-left: 30px">

            <h3>Caracteristicas:</h3>

            <ul>
              <li><strong>Modelo apropiativo:</strong> Los hilos deben operar bajo la suposición de que su ejecución
                puede verse interrumpida por el sistema operativo en cualquier momento.</li>
              <li><strong>Posibilidad de recursos compartidos:</strong> Diferentes hilos en un proceso pueden acceder a
                la misma región de memoria, o descriptores de archivos comunes (entre otros).</li>
              <li><strong>Soporte directo al paralelismo:</strong> Se puede asumir con confianza que usar hilos en un
                sistema multiprocesador lleva a una mayor utilización de esta característica. </li>
            </ul>

            <h3>Diseño:</h3>

            <ul>
              <li><strong>Creación de un hilo: </strong> La abstracción básica es la ejecución de una función como punto
                de entrada para un hilo individual, y la obtención de un recurso vinculado a dicha ejecución. Un hilo
                puede comenzar con:</li>
              <ul>
                <li>Un puntero a una función</li>
                <li>Una clausura</li>
                <li>Un método en un objeto</li>
              </ul>
              <p>Un hilo se puede monitorear con:</p>
              <ul>
                <li>Un identificador en una tabla</li>
                <li>Un objeto nuevo</li>
                <li>El estado del objeto que la crea</li>
              </ul>
              <li><strong>Comunicación: </strong> Los hilos se pueden comunicar por medio de memoria compartida. Para
                asegurar que esta memoria es accedida de manera correcta, se provee al programador con primitivas de
                sincronización: semáforos, exclusiones mutuas, tipos atómicos.</li>
            </ul>

            <h2>
              <a id="multiprogramación" class="anchor" href="#multiprogramaci%C3%B3n" aria-hidden="true"><span
                  aria-hidden="true" class="octicon octicon-link"></span></a>Multiprogramación
            </h2>

            <p>Es una técnica de multiplexación que permite de múltiples procesos en un único procesador.
              Es importante resaltar que los procesos nunca corren en paralelo en el procesador, ya que en cada instante
              de tiempo solo se ejecuta un proceso en el procesador.</p>

            <h2>
              <a id="multiproceso" class="anchor" href="#multiproceso" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Multiproceso
            </h2>

            <p>Es una técnica en la cual se hace uso de dos o más procesadores en una computadora para ejecutar uno o
              varios procesos.</p>

            <h2>
              <a id="corrutinas" class="anchor" href="#corrutinas" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Corrutinas
            </h2>

            <p>
              Una corrutina es un componente de programación concurrente que permite la ejecución cooperativa de múltiples tareas en un mismo hilo de ejecución. A diferencia de los hilos tradicionales, donde el sistema operativo es responsable de la planificación y la asignación de tiempo de ejecución, las corrutinas son controladas por el programador y pueden ceder el control de manera explícita.
            </p>

                      
            <h3>Características:</h3>

            <ul>
              <li><strong>Modelo cooperativo:</strong> Las corrutinas tienen que ser programadas de manera que cedan la
                ejecución en momentos apropiados, y eviten acaparar recursos.</li>
              <li><strong>Contextos ligeros: </strong> Las corrutinas requieren un uso de memoria considerablemente
                menor, gracias a que no definen el contexto completo: un solo hilo de S.O. puede aprovisionar múltiples
                corrutinas.</li>
              <li><strong>Soporte opcional de paralelismo:</strong> Las corrutinas suelen modelar la concurrencia como
                un cambio de contexto dentro de un mismo hilo, sin embargo, es probable que un runtime moderno permita
                configurar para usar múltiples hilos. </li>
            </ul>

            <h3>Diseño:</h3>

            <ul>
              <li><strong>Cooperación </strong> Deben existir constructos en el lenguaje (palabras clave, interfaces, u
                otros) que permitan señalizar el punto en el que una corrutina cede la ejecución.</li>
              <p>Algunas formas de sintaxis que pueden permitir esto:</p>
              <ul>
                <li>Funciones que retornan handles, con métodos adecuados.</li>
                <li>Objetos compartidos que monitorean el estado de cada subrutina.</li>
                <li>Palabras claves que indican la oportunidad para cambiar de contexto, como yield o await.</li>
              </ul>
            </ul>

            <h2>
              <a id="eventLoop" class="anchor" href="#eventLoop" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Event Loop
            </h2>


            <h3>Caracteristicas:</h3>

            <ul>
              <li><strong>Modelo bloqueante deferido:</strong> Se establece un mecanismo para registrar la ocurrencia de
                eventos y la ejecución de tareas en respuesta a diferentes tipos de eventos, al final de un ciclo de
                ejecución.</li>
              <li><strong>Concurrente, no paralelo por defecto: </strong> Este modelo permite describir la ocurrencia de
                diferentes eventos intercaladamente en un sólo hilo, y responder a eventos que serían bloqueantes con el
                registro de un evento. De esta manera se consigue un uso óptimo de recursos, pero no se modela el acceso
                a capacidades paralelas.</li>
              <li><strong>Memoria local</strong> El alcance de los recursos es análogo al de un programa secuencial.
              </li>
            </ul>

            <h3>Diseño:</h3>

            <p>
              El registro de acciones a ejecutar en respuesta a eventos tiene una solución que se ajusta perfectamente:
              las clausuras.</br>

              Sin embargo, el uso de clausuras para el uso de los valores resultantes de computaciones deferidas tiene
              problemas de ergonomía (véase: pirámide de la perdición).</br>

              Alternativas:
            </p>

            <ul>
              <li><strong>Promesas/Futuros: </strong> Objetos con métodos adecuados.</li>
              <li><strong>Async/Await: </strong> Palabras claves para describir computaciones deferidas.</li>
            </ul>

            <h2>
              <a id="actores" class="anchor" href="#actores" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Actores
            </h2>
          
            <p>
              En el contexto de la programación concurrente, un actor es una entidad de ejecución independiente que encapsula su propio estado y procesamiento. Los actores se comunican entre sí a través del intercambio de mensajes, y cada actor tiene una cola de mensajes asociada. Cada mensaje recibido es procesado secuencialmente por un único actor a la vez, lo que evita problemas de concurrencia como las condiciones de carrera.

            </p>

            <h3>Características:</h3>

            <ul>
              <li><strong>Procesos ligeros:</strong> Un actor es una unidad de procesamiento análoga al proceso, pero
                manejada por un proceso del S.O. real: la máquina virtual del lenguaje de programación. Gracias a esto,
                cada actor es extremadamente pequeño.</li>
              <li><strong>Modelo apropiativo: </strong> La máquina virtual actúa como el árbitro de la ejecución de los
                actores, deteniendo su ejecución de acuerdo a medidas globales.</li>
              <li><strong>Paralelismo:</strong> Según las capacidades de la máquina virtual, el paralelismo puede ser
                tan automático como al usar hilos. </li>
            </ul>

            <h3>Diseño:</h3>

            <p>El modelo de actores establece que estas unidades mínimas no comparten memoria, y su viabilidad es
              independiente de la de los otros. Esto implica:</p>

            <ul>
              <li><strong>Comunicación por mensajes: </strong> los actores se informan de su estado y solicitan
                computaciones a partir de mensajes, y, por tanto, no comparten memoria mutable.</li>
              <li><strong>Pureza: </strong> Los actores solo conocen su estado interno, y los mensajes que obtienen del
                exterior, que pueden pensarse como argumentos a una función pura. De ahí la capacidad de paralelismo.
              </li>
              <li><strong>Manejo de errores optimista: </strong> los errores causados por condiciones inusuales y
                transitorias son manejados reiniciando un actor, manteniendo el programa global en curso. </li>
            </ul>

            <h2>
              <a id="procesamiento-distribuido" class="anchor" href="#procesamiento-distribuido"
                aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Procesamiento
              distribuido
            </h2>

            <p>Es cuando uno o varios procesos son ejecutados en una o más computadores</p>

            <h2><a id="calendarizacion" class="anchor" href="#proceso" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Planificación De Procesos</h2>

            <p>Estrategia de los sistemas operativos con la que se es posible compartir la CPU entre los diferentes
              procesos alojados en memoria.
              La calendarización es un manejo de colas con el objetivo de maximizar el uso de recursos y minimizar
              retardos.</p>

            <img src="images/calendarizacion.png" style="display: block; margin-right: auto; margin-left: auto;">
            <h3>Tipos de Calendarización</h3>

            <h4>Calendarización a corto plazo</h4>
            <ul>
              <li>Determina cuáles programas son admitidos al sistema para la ejecución.</li>
              <li>El objetivo principal es mantener una mezcla balanceada de tareas, como los límites de entrada/salida
                y de procesador.</li>
              <li>Controla el nivel de multiprogramación.</li>
            </ul>

            <h4>Calendarización a mediano plazo</h4>
            También conocido como CPU scheduler o dispatcher. Su principal objetivo es incrementar el rendimiento del
            sistema acorde a un criterio definido.
            <br><b>Dispatch latency:</b> Tiempo que toma entre parar un proceso y empezar otro.

            <h4>Calendarización a largo plazo</h4>
            <ul>
              <li>Hace parte del swapping del sistema.</li>
              <li>Agrega y remueve procesos de memoria.</li>
              <li>Reduce el nivel de multiprogramación del sistema.</li>
            </ul>

            <h3>Cambios de contexto</h3>

            Mecanismo para almacenar y restaurar el estado de un proceso.

            <ul>
              <li>Registers</li>
              <li>Stack pointer</li>
              <li>Program counter</li>
            </ul>

            <div class="center">
              <p><img src="https://www.tutorialspoint.com/operating_system/images/context_switch.jpg"
                  alt="Cambio de contexto"
                  style="display: block; margin-right: auto; margin-left: auto;"></p>
            </div>

            <h3>Criterios de Calendarización</h3>

            <ul>
              <li><strong>Utilización de CPU:</strong> mantener el CPU lo más ocupado posible</li>
              <li><strong>Throughput:</strong> Procesos completados por unidad de tiempo</li>
              <li><strong>Tiempo de vuelta:</strong> tiempo en completar un proceso en específico</li>
              <li><strong>Tiempo de espera:</strong> tiempo en el que un proceso ha estado en la cola de ready</li>
              <li><strong>Tiempo de respuesta:</strong> tiempo que toma desde la creación del proceso hasta su primera
                respuesta</li>
            </ul>

            <h3>Algoritmos de Calendarización</h3>

            <div class="text-justify">
              <p>El principal objetivo de los algoritmos de calendarización es asignar tiempos de ejecución a los
                procesos del sistema para optimizar uno o más aspectos del mismo.</p>
            </div>
            <ul>
              <li><strong>First-Come, First-Served (FCFS)</strong></li>
              <p>Algoritmo simple de calendarización, en el que asigna el procesador según el orden de llegada a la cola
                de ready y lo ejecuta hasta el final,
                como ventajas tienen un buen throughput y tiempo de vuelta, como desventajas malos tiempos de respuesta
                y de espera, en cuanto a utilización de CPU
                tiene la ventaja de que hace pocos cambios de contexto, mas se desaprovecha el CPU cuando los procesos
                tienen que esperar a entradas y/o salidas.</p>
              <!-- <p><img src="https://s18.postimg.org/cvdn2v4ft/fcfs1.jpg" style="margin-left: 30px"></p>
  <p><img src="https://s7.postimg.org/5ng6kqtx7/fcfs.jpg" style="margin-left: 30px"></p> -->
              <li><strong>Shortest-Job-First (SJF)</strong></li>
              <p>con SJF se ejecuta primero el proceso con menor tiempo de ejecución que se encuentre en la cola de
                ready, a comparación de FCFS tiene
                mejor tiempo de respuesta, mejor throughput, menores tiempos de espera, en cuanto a uso del CPU se
                comporta igual a FCFS, como desventaja tiene
                la dificultad de predecir el tiempo de ejecución de un proceso. </p>
              <!-- <p><img src="https://s24.postimg.org/mjnlamwp1/sjf1.jpg" style="margin-left: 30px"></p>
  <p><img src="https://s12.postimg.org/guh11mzi5/sjf.jpg" style="margin-left: 30px"></p> -->
              <li><strong>Priority Scheduling</strong></li>
              <p>Introduce una necesidad en el que unos procesos deben tener prioridad sobre otros, para ello asocia un
                numero indicando el nivel de prioridad a cada proceso
                cuando están en la cola de ready selecciona el de mayor prioridad, como desventaja los procesos con baja
                prioridad podrían sufrir de starvation
                tardando mucho o nunca saliendo de la cola de ready, esto se soluciona utilizando una técnica en la que
                a medida que va pasando el tiempo se incrementa
                la prioridad de un proceso en la cola, por lo que aquellos que lleven mucho tiempo en esta irán
                aumentando su prioridad. Dependiendo de las prioridades
                que se le asignen a cada proceso puede tener buenos o malos tiempos. Hay que tener en cuenta que si
                ningún otro proceso está en la cola de ready ejecutara
                el único que haya en la cola, más en el momento que llegue un proceso con mayor prioridad se sacara de
                ejecución el de menor y el CPU lo ocupara el que acaba
                de llegar con mayor prioridad, esto se evidencia en el ejemplo a continuación:</p>
              <!-- <p><img src="https://s28.postimg.org/o9zd19hod/priority.jpg" style="margin-left: 30px"></p>
  <p><img src="https://s14.postimg.org/k1wtmwtq9/priority2.jpg" style="margin-left: 30px"></p> -->
              <li><strong>Round Robin (RR)</strong></li>
              <p>Se asigna un tiempo de CPU (time quantum) para todos los procesos, estos se ejecutarán durante ese
                tiempo según el orden de llegada, en cuanto completan el tiempo
                asignado se sacan de ejecución y se regresan a la cola de ready, este procedimiento se repite hasta que
                el proceso complete toda su ejecución. Como
                ventaja tiene bajos tiempos de espera y de respuesta, peor tiempo de vuelta y throughput mas bajo que
                SJF, el uso del CPU baja por el mayor numero
                de cambios de contexto que debe hacer, por lo que es importante escoger un buen time quantum, si se
                escoge un tiempo muy corto habrá muchos cambios de contexto
                y los procesos tardaran mucho más en terminar, si se escoge muy grande se perderían las ventajas del
                algoritmo, se suele usar tiempos de 10ms a 100ms, también
                hay que tener en cuenta que para que sea optimo este tiempo debe ser mayor al que tarda el procesador en
                hacer un cambio de contexto. </p>
              <!-- <p><img src="https://s14.postimg.org/b4jih3wzl/image.jpg" style="margin-left: 30px"></p>
  <p><img src="https://s23.postimg.org/smstmzwnv/rr2.jpg" style="margin-left: 30px"></p> -->
              <li><strong>Multiple-Level Queues</strong></li>
              <p>la cola de ready se parte en varias colas que determinan la prioridad de los procesos, cada cola
                implementa su propio algoritmo de calendarización y
                adicionalmente también se hace calendarización entre las colas</p>
              <!-- <p><img src="https://s11.postimg.org/ac3tmerfn/multiqueue.jpg" style="margin-left: 30px"></p> -->
            </ul>

            <h3>Ejemplo Algoritmos de Calendarización</h3>
            <p>En la figura se puede ver cómo son atendidos 5 procesos según cada algoritmo.</p>
            <img src="images/concurrentAl.png" style="margin-left: 30px">
            <div id="ejecucion-concurrente" href="#ejecucion-concurrente">
              <br> <br>
              <h1>¿Qué se puede ejecutar concurrentemente?</h1>
              No todas las partes de un programa se pueden ejecutar concurrentemente:
              <br><br><img src="images/tabla.png" style="display: block; margin-right: auto; margin-left: auto;"><br><br>
              <ul>
                <li>En la primera columna está claro que la primera sentencia se debe ejecutar antes que la segunda</li>
                <li>En la segunda columna, el orden en que se ejecuten no tiene importancia</li>
              </ul>
              En general existen unas condiciones para saber que se puede ejecutar concurrentemente:
              <strong>Condiciones de Bernstein.</strong><br><br>
              <h2>Condiciones de Bernstein</h2>
              Para poder determinar si dos conjuntos de instrucciones se pueden ejecutar concurrentemente, sea Sk un
              conjunto
              de instrucciones a ejecutar, llamamos:
              <ul>
                <li>L(Sk) = {a1, a2, ...an} al conjunto de lectura, formado por todas las variables cuyos valores son
                  referenciados
                  (se leen) durante la ejecución de las instrucciones Sk.</li>
                <li>E(Sk) = {b1, b2, ...bm} al conjunto de escritura, formado por todas las variables cuyos valores son
                  actualizados
                  durante la ejecución.</li>
              </ul>
              Para que se puedan ejecutar concurrentemente dos conjuntos de instrucciones Si y Sj se debe cumplir que
              ninguno escriba
              lo que el otro lee o escribe:
              <br><br><img src="images/condiciones.png" style="display: block; margin-right: auto; margin-left: auto;"><br><br>
            </div>

            <h1>Problemas de los programas concurrentes</h1>
            <p>Al lidiar con varias tareas al tiempo los programas concurrentes pueden presentar varios problemas : </p>
            <ul>
              <li>
                <strong>Violación de la exclusión mutua : </strong> Como se menciono anteriormente, es cuando más de un
                hilo trata de ejecutar la sección critica de un programa
                y lo logra, obteniendo asi resultados indeseados. Por ejemplo, tenemos una expresión de tipo:
                <br>
                <strong>x = x + 1</strong>
                <br>
                Donde x tiene un valor inicial de 6, entonces al haber violación de exclusión mutua, varios hilos
                podrian tomar una copia local de x, añadir 1 y todos
                devuelven 7 a x, lo cual es algo que no se quiere.<br>
                Un ejemplo que replica este problema en Java, un contador que al final deberia dar 1000000, pero siempre
                arroja diferentes resultados: <br>
                <pre class="prettyprint">
      // Ejemplo hecho para ilustrar la mutabilidad del estado compartido de los hilos.
      // Muestra un resultado distinto cada vez que se corre el programa

      public class Counting {
        public static void main(String[] args) throws InterruptedException {
        class Counter {
        int counter = 0;
        public void increment() { counter++; }
        public int get() { return counter; }
        }
        final Counter counter = new Counter();

        class CountingThread extends Thread {
        public void run() {
        for (int x = 0; x < 500000; x++) {
        counter.increment();
        }
        }
        }

        CountingThread t1 = new CountingThread();
        CountingThread t2 = new CountingThread();
        t1.start(); t2.start();
        t1.join(); t2.join();
        System.out.println(counter.get());//deberia dar 1000000
        }
      }
    </pre>

                Y el resultado es: <br>
                <pre class="prettyprint">
      Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp/ -Xms64m
      883345
      ~/Java$ java Counting
      Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp/ -Xms64m
      830292
      ~/Java$ java Counting
      Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp/ -Xms64m
      1000000
      ~/Java$ java Counting
      Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp/ -Xms64m
      964409
      ~/Java$ java Counting
      Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp/ -Xms64m
      945471
      ~/Java$ java Counting
      Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp/ -Xms64m
      961164
      ~/Java$
    </pre>
                Esto se debe a que no hay un orden total como sucede en la
                programación secuencial, hay un orden parcial, lo que genera
                un orden de precedencia de las instrucciones que se deben ejecutar
                muy diferente, de tal manera que en dicho árbol se muestra un orden
                de ejecución simultáneo para todas las instrucciones del programa.
                <p><center><img src="images/arbol_precedencia.PNG" alt=""></center></p><br><br>


              </li>
              <li>
                <strong>Deadlock : </strong> Tambien conocido como abrazo mortal, ocurre cuando un proceso espera un
                evento que nunca va a pasar. Aunque se puede dar por
                comunicación entre procesos , es más frecuente que se de por manejo de recursos. En este caso, deben
                cumplirse 4 condiciones para que se de un "deadlock" :
                <ul>
                  <li>Los procesos deben reclamar un acceso exclusivo a los recursos.</li>
                  <li>Los procesos deben retener los recursos mientras esperan otros.</li>
                  <li>Los recursos pueden no ser removidos de los procesos que esperan.</li>
                  <li>Existe una cadena circular de procesos donde cada proceso retiene uno o más recursos que el
                    siguiente proceso de la cadena necesita.</li>
                </ul>
                Las técnicas utilizadas para evitar estos problemas consisten en negar una de las cuatro condiciones
                anteriormente mencionadas.<br>
                Un ejemplo que replica este problema es este de a continuación, escrito en Ada. Aqui dos procesos se
                ejecutan de manera finita, mientras que otros dos, los que hacen los llamados
                funcionan en un ciclo infinito y al final se quedan esperando algo que nunca va a ocurrir: <br>
                <pre class="prettyprint">

      with Ada.Text_IO;
      use Ada.Text_IO;
      procedure Meals1 is

        HOURS : constant := 1;
        type PERSON is (BILL, JOHN);

        package Enum_IO is new Ada.Text_IO.Enumeration_IO(PERSON);
        use Enum_IO;

        task Bills_Day;

        task Johns_Day;

        task Restaurant is
        entry Eat_A_Meal(Customer : PERSON);
        end Restaurant;

        task Burger_Boy is
        entry Eat_A_Meal(Customer : PERSON);
        end Burger_Boy;

        task body Bills_Day is
        My_Name : PERSON := BILL;
        begin
        delay 1.0 * HOURS;
        Restaurant.Eat_A_Meal(My_Name);
        delay 1.0 * HOURS;
        Restaurant.Eat_A_Meal(My_Name);
        delay 1.0 * HOURS;
        Restaurant.Eat_A_Meal(My_Name);
        end Bills_Day;

        task body Johns_Day is
        My_Name : PERSON := JOHN;
        begin
        delay 0.4 * HOURS;
        Restaurant.Eat_A_Meal(My_Name);
        delay 0.4 * HOURS;
        Restaurant.Eat_A_Meal(My_Name);
        delay 4.0 * HOURS;
        Restaurant.Eat_A_Meal(My_Name);
        end Johns_Day;

        task body Restaurant is
        begin
        loop
        accept Eat_A_Meal(Customer : PERSON) do
        Put(Customer);
        Put_Line(" esta ordenando en el restaurante");
        delay 0.5 * HOURS;
        Put(Customer);
        Put_Line(" esta comiendo en el restaurante");
        delay 0.5 * HOURS;
        end Eat_A_Meal;
        end loop;
        end Restaurant;

        task body Burger_Boy is
        begin
        loop
        accept Eat_A_Meal(Customer : PERSON) do
        Put(Customer);
        Put_Line(" esta ordenando en el McDonalds");
        delay 0.1 * HOURS;
        Put(Customer);
        Put_Line(" esta comiendo en el McDonalds");
        delay 0.1 * HOURS;
        end Eat_A_Meal;
        end loop;
        end Burger_Boy;

      begin
        null;
      end Meals1;
    </pre>
                Y el resultado es:
                <pre class="prettyprint">
      JOHN esta ordenando en el restaurante
      JOHN esta comiendo en el restaurante
      BILL esta ordenando en el restaurante
      BILL esta comiendo en el restaurante
      JOHN esta ordenando en el restaurante
      JOHN esta comiendo en el restaurante
      BILL esta ordenando en el restaurante
      BILL esta comiendo en el restaurante
      BILL esta ordenando en el restaurante
      BILL esta comiendo en el restaurante
      JOHN esta ordenando en el restaurante
      JOHN esta comiendo en el restaurante


    </pre>
                Se queda atascado en medio de la ejecución.
              </li>
              <li>
                <strong>Aplazamiento indefinido : </strong> O tambien conocido como "starvation" o "lockout", se da
                cuando el algoritmo que maneja los recursos no tiene en cuenta
                el tiempo que lleva esperando ese proceso. Para solucionar esto entre procesos que compiten se puede
                manejar de tal manera que mientras más espere un proceso, más
                alta será su prioridad, aunque una solución más sencilla y aplicable a un rango mayor de circunstancias
                es tratar con los procesos estrictamente en su orden de espera.<br>
                Un ejemplo en Ada es el siguiente, en este, un hilo se queda esperando una respuesta de otro proceso que
                nunca va a ocurrir por que la tarea Gourmet
                ya acabo, y por eso no va a ser llamada:

                <pre class="prettyprint">

        with Ada.Text_IO;
        use Ada.Text_IO;

        procedure HotDog is

          task Gourmet is
          entry Make_A_Hot_Dog;
          end Gourmet;

          task body Gourmet is
          begin
          Put_Line("Voy a preparar un perro caliente");
          for Index in 1..5 loop --si se cambia el 4 por un 5 se entrará en inanicion porque el task main del procedure hotdog no recibira la llamada
          accept Make_A_Hot_Dog do
          delay 0.8;
          Put("Pongo el perro caliente en la mesa ");
          Put_Line(" y le pongo mostaza");
          end Make_A_Hot_Dog;
          end loop;
          Put_Line("ya no quiero mas perros calientes");
          end Gourmet;

        begin
          for Index in 1..4 loop
          Gourmet.Make_A_Hot_Dog;
          delay 0.1;
          Put_Line("como lo que me queda de perro caliente");
          New_Line;
          end loop;
          Put_Line("ya estoy lleno");
        end HotDog;
    </pre>
                Y su resultado es:
                <pre class="prettyprint">
      Voy a preparar un perro caliente
      Pongo el perro caliente en la mesa y le pongo mostaza
      como lo que me queda de perro caliente

      Pongo el perro caliente en la mesa y le pongo mostaza
      como lo que me queda de perro caliente

      Pongo el perro caliente en la mesa y le pongo mostaza
      como lo que me queda de perro caliente

      Pongo el perro caliente en la mesa y le pongo mostaza
      como lo que me queda de perro caliente

      ya estoy lleno
    </pre>
              </li>
              <li>
                <strong>Injusticia : </strong> también conocido como "unfairness", ocurre cuando el programa no tiene
                mecanismos para asegurar que se da un progreso "parejo" en las
                tareas concurrentes, este es un aspecto que el diseñador debe tener en cuenta al desarrollar el
                programa, cualquier descuido a la "justicia" de un programa podría
                generar un aplazamiento indefinido.
              </li>
              <li>
                <strong>False sharing:</strong>
                <p>
                Es un fenómeno en programación concurrente en el cual dos o más hilos o procesos, que trabajan en diferentes partes de la memoria, comparten una caché. Aunque están modificando datos independientes, debido a la arquitectura de la caché, las actualizaciones de una región de memoria pueden invalidar la caché de otra región, haciendo necesaria una nueva sincronización, resultando en un rendimiento subóptimo y problemas de concurrencia.
                </p>
                <p>
                  En arquitecturas de computadoras modernas, la memoria se organiza en líneas de caché. Si dos hilos modifican datos ubicados en la misma línea de caché, aunque sean datos diferentes, la caché podría invalidarse continuamente, generando un overhead innecesario.
                </p>
                <p>
                  El false sharing puede tener un impacto significativo en el rendimiento, ya que puede resultar en una mayor competencia por recursos de caché y la invalidación frecuente de cachés. Esto puede llevar a un aumento en el tiempo de ejecución y una disminución de la eficiencia del programa.
                </p>
                <p>
                  Para mitigar el false sharing, se pueden emplear varias estrategias:
                  <ul>
                    <li>
                      <strong>Alineación de Variables: </strong> Asegurarse de que las variables utilizadas por hilos concurrentes estén alineadas de manera que ocupen diferentes líneas de caché.
                    </li>
                    <li>
                      <strong>Padding: </strong>Agregar relleno (padding) entre variables para separarlas en líneas de caché diferentes y evitar la interferencia entre ellas.
                    </li>
                    <li>
                      <strong>Técnicas de Optimización del Compilador: </strong>Algunos compiladores ofrecen opciones para alinear variables y optimizar la disposición en la memoria.
                    </li>
                  </ul> 
                </p>
                <p>
                  A continuación se presenta una demostración visual del problema del uso compartido de memoria caché False Sharing:
                </p>
                <p>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/kMRLgCtxjvg?si=tIYcDtHWUxSIFar7" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                </p>
              </li>
            </ul>

            Para una mayor información de como funcionan y actúan estos problemas, por favor referirse al notebook
            dejado a continuación: <br>
            <h3><a
                href="http://nbviewer.jupyter.org/url/ferestrepoca.github.io/paradigmas-de-programacion/progconcurrente/concurrente_teoria/notebook/Notebook_ProgConcurrente_20181.ipynb"
                target="_blank">Notebook problemas prog. concurrente</a></h3>

            <h1>
              <a id="propiedades" class="anchor" href="#propiedades" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Propiedades de los programas concurrentes
            </h1>
            Los requerimientos que deben haber para que un programa concurrente sea exitoso se pueden definir en
            terminos de propiedades que posee, y estas a su vez se clasifican en propiedades de
            <i>seguridad</i> y de <i>vida</i>.

            <h2>Seguridad</h2>
            Indican que es lo que se le permite hacer al programa, o equivalentemente, lo que no deberia hacer.
            <ul>
              <li><strong>Exclusión mutua :</strong> Solo hay un proceso presente en una sección critica, aunque esto
                puede llegar a ser contraproducente al momento de la ejecución.</li>
              <li><strong>No deadlock :</strong> Ningun proceso debe ser retrasado esperando un evento que nunca va a
                ocurrir.</li>
              <li><strong>Correctitud parcial :</strong> Si el programa termina, la salida sera lo es requerido.</li>
            </ul>
            Estas propiedades de seguridad son expresadas como <strong>invariantes</strong> en computacion, es decir,
            son condiciones que se mantienen ciertas en todos los puntos de ejecución del programa.

            <h2>Vida</h2>
            Estas propiedades indican lo que el programa debe hacer; lo que ocurrira eventualmente.
            <ul>
              <li><strong>Justicia :</strong> Un proceso que puede ser ejecutado, va a ser ejecutado.</li>
              <li><strong>Comunicación confiable :</strong> Un mensaje enviado por un proceso sera recibido por otro.
              </li>
              <li><strong>Correctitud completa :</strong> Cuando el programa termina, el resultado obtenido es el
                resultado requerido.</li>
            </ul>

            <h1>
              <a id="sincronizacion" class="anchor" href="#sincronizacion" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Sincronizacion
            </h1>

            <p>Cuando tenemos varios procesos o hilos en la ejecución, en muchos casos no queremos que estos se ejecuten
              al mismo tiempo. El mecanismo que controla el orden de ejecución de determinadas tareas lo llamamos
              <strong>SINCRONIZACION</strong>.
            </p>

            <p><em><strong>¿Por qué el algunos casos no queremos que los hilos se ejecuten al mismo
                  tiempo?</strong></em></p>

            <div class="center">
              <p><img src="http://www.blogdepsicologia.com/wp-content/uploads/2015/06/ansiedad-2.jpg" alt=""></p>
            </div>
            <p><em><strong>porque se dan condiciones de carrera.</strong></em></p>
            <h2>
              <a id="condicion de carrera" class="anchor" href="#condicion de carrera" aria-hidden="true"><span
                  aria-hidden="true" class="octicon octicon-link"></span></a>Condición de carrera
            </h2>

            <p>
              “Una condición de carrera es un comportamiento del software en el cual
              la salida depende del orden de ejecución de eventos que no se encuentran
              bajo control”
            </p>

            <ul>
              <li>
                Se da cuando uno o más hilos ejecutan secciones que otro hilo podría usar al mismo tiempo, y en estas
                modifica variables que podrían afectar la ejecución del resto de hilos.
              </li>

              <li>
                Se pueden producir cuando varios threads NO acceden en exclusión mutua a un recurso compartido.
              </li>

              <li>
                El nombre viene de la idea de dos procesos compiten en una carrera para acceder a un recurso compartido.
              </li>

              <li>
                Se convierte en un fallo siempre que el orden de ejecución no sea el esperado.
              </li>
            </ul>

            <h2>
              <a id="problema-del-lector---escritor" class="anchor" href="#problema-del-lector---escritor"
                aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Problema del Lector
              - Escritor
            </h2>

            <p>Cuando tenemos varios lectores y escritores, por ejemplo, en un base de datos, muchos procesos van a
              intentar leer o escribir al mismo tiempo, lo cual no podemos permitir, ya que, nuestra informacion se
              podria perder, duplicar, corromper entre otros. Solo es posible que un proceso leo o escriba y que los
              demas esperen su turno. </p>
            <p><center><img src="images/problema_lector_escritor.PNG" alt=""></center></p><br><br>

            <h2>
              <a id="problema-productor-consumidor" class="anchor" href="#problema-productor-consumidor"
                aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Problema del
              Productor - Consumidor
            </h2>

            <p>Existen uno o más productores y uno o más consumidores, todos almacenan y extraen productos de una misma
              bodega. El productor produce productos cada vez que puede, y el consumidor los consume cada vez que lo
              necesita.
            </p>
            <p>
              Problema:<br>
              ¿Cómo coordinamos a los productores y consumidores, para que los productores no produzcan más ítems de los
              que se pueden almacenar en el momento, y los consumidores no adquieran más ítems de los que hay
              disponibles?. </p>
            <br>
            <p>
              Solucion:<br>
              Desde el punto de vista de la programación concurrente la solución a este problema se plantea a través de
              herramientas de sincronización. La primera solución y la más sencilla es implementar bodegas que sean
              excluyentes, es decir si un consumidor o productor se encuentra haciendo de la bodega, nadie más pueda
              hacerlo, indicando este estado con cualquier tipo de señal o aviso, implementado a través de semáforos
              binarios, cuyo concepto también es explicado en esta página.</p>
            <p>
              La anterior solución aunque es funcional y completamente viable, no es del todo acertada, luego de
              profundizar en el enfoque de la programación concurrente se destaca que tiene fallos muy probables, debido
              a que puedo agregar más actores a este ambiente, y si solo uno de estos no aplica la metodología del
              semáforo de manera acertada la información se corromperá, además de contener un bloque de código igual en
              todos los consumidores y productores. Para solucionar esto se plantea una solución a través de un monitor
              el cual se encargará de revisar los procesos de compra y producción, eliminando así el código clonado,
              además de organizar los procesos desde el objeto de las bodegas en sí.</p>

			<h2>Punto Muerto e Interbloqueo</h2>

            <p>Se dice que un proceso está en punto muerto si se está esperando un evento que no ocurrirá. 
				Un interbloqueo, por lo general, implica varios procesos y puede conducir a la terminación del programa. 
				El interbloqueo puede ocurrir cuando los procesos se comunican (por ejemplo, dos procesos intentan 
				enviarse mensajes entre sí de manera simultánea y sincrónica) pero es un problema más frecuentemente 
				asociado con administración de recursos. En este contexto son necesarios cuatro condiciones para que 
				exista un interbloqueo:</p>

                <ul>
					<li>Los procesos deben reclamar el acceso exclusivo a los recursos.</li>
  
					<li>Los procesos deben contener algunos recursos mientras esperan otros (es decir,
						adquirir recursos de forma fragmentaria).</li>
  
					<li>Los recursos no pueden eliminarse de los procesos en espera (sin preferencia).</li>
  
					<li>Existe una cadena circular de procesos en la que cada proceso tiene uno o más recursos requeridos por el siguiente proceso en la cadena.</li>
				  </ul>

				  <p>Las técnicas para evitar (o recuperarse de) un punto muerto se basan en negar, al menos, una de estas condiciones. 
					Una de las mejores técnicas (aunque poco prácticas) para evitar interbloqueos es el algoritmo del banquero de Dijkstra. 
					Dijkstra también planteó lo que se ha convertido en un clásico ejemplo ilustrativo en este campo: el de los "filósofos gastronómicos".
					</p>

			<h2>Aplazamiento indefinido (o inanición o cierre patronal)</h2>

			<p>Se dice que un proceso se pospone indefinidamente si se retrasa esperando un evento que puede no ocurrir. Esta situación puede surgir cuando las solicitudes del  recurso se administran utilizando un algoritmo que no hace provisión por el tiempo de espera de los procesos involucrados. 
				Las técnicas para evitar el problema colocan procesos competitivos en un orden de prioridad tal que cuanto más tiempo espera un proceso, mayor es su se convierte en prioridad. Tratar los procesos estrictamente en su orden de demora es una solución más simple que es aplicable en muchas circunstancias. para una discusión de estas técnicas.
				</p>

			<h2>Injusticia</h2>

			<p>En general, se cree que cuando existe competencia entre procesos de igual estatus en un programa concurrente, se debe hacer algún intento para asegurar que los procesos en cuestión progresen uniformemente; es decir, para asegurar que no haya injusticia manifiesta al momento de satisfacer las necesidades de esos procesos. La equidad en un sistema concurrente se puede considerar tanto a nivel de diseño como de implementación del sistema. Para el diseñador es simplemente una pauta a observar al desarrollar un programa; cualquier descuido de la equidad puede conducir a un aplazamiento indefinido, dejando el programa incorrecto.
					Para un implementador del sistema es nuevamente una guía. La mayoría de los lenguajes de programación concurrentes no abordan la equidad. En cambio, el problema se deja en manos de los escritores del compilador y los desarrolladores del software de soporte en tiempo de ejecución					
					</p>

			<h2>Ocupado Esperando</h2>

			<p>Independientemente del entorno en el que se desarrolle un programa concurrente ejecutado, rara vez es aceptable que cualquiera de sus procesos ejecute un bucle en espera de un cambio de estado del programa. Esto se conoce como "ocupado esperando". Las variables de estado involucradas constituyen un bloqueo de giro. No es en sí mismo un error, pero desperdicia energía del procesador, lo que a su vez puede conducir a la violación de un requisito de desempeño. Idealmente, la ejecución del proceso en cuestión debe suspenderse y continuar sólo cuando se cumple la condición para que progrese.
						</p>

			<h2>Errores transitorios</h2>

			<p>En presencia de no determinismo, las fallas en un programa concurrente
							pueden aparecer como errores transitorios; es decir, el error puede ocurrir o no
							dependiendo de la ruta de ejecución tomada en una activación particular del programa. La causa de un error transitorio tiende a ser difícil de identificar porque los eventos que lo preceden a menudo no se conocen precisamente y la fuente del error no puede, en general, ser encontrada por experimentación. Así, una de las habilidades en el diseño de cualquier
							programa concurrente es la habilidad de expresarlo en una forma que garantiza el comportamiento correcto del programa a pesar de cualquier incertidumbre sobre el orden en que se realizan algunas operaciones individuales. Eso es, no debe haber ninguna parte del programa cuyo comportamiento correcto depende del tiempo.
							
							</p>
						
            <h2>Sección Critica</h2>

            <p>Para solucionar estos inconvenientes hay que identificar las secciones de código en las que se pueden dar
              condiciones de carrera y permitir que solo un hilo
              entre a estas secciones a la vez. Podríamos pensar en un cruce de autos como una sección critica, en la
              que los autos que vayan en otro sentido no podrán
              ingresar al cruce hasta que los carros del carril que tiene el semáforo en verde (tienen permiso de entrar
              a la sección critica) terminen de pasar.</p>

              <h2>
                <a id="problema-de-los-filosofos-que-cenan" class="anchor" href="#problema-de-los-filosofos-que-cenan"
                  aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>La cena de los filósofos
              </h2>
  
              <div class="center">
                  <p><center><img
                    src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/An_illustration_of_the_dining_philosophers_problem.png/200px-An_illustration_of_the_dining_philosophers_problem.png"
                    alt=""></center></p>
              </div><br><br>
  
              <p>El problema de la cena de los filósofos es una de las analogías más populares usadas para explicar la concurrencia,
                sus problemas y acciones de mitigación. Existen n filósofos, n tenedores, y n platos de pasta en la mesa. Dicha pasta
                debe comerse con dos tenedores, por lo que en el caso inicial, <b>no todos pueden comer a la vez</b>. Entonces, los
                filósofos compiten por obtener los tenedores en un tiempo corto, porque de lo contrario morirán de hambre. Una vez
              un filósofo termina de comer, suelta ambos tenedores.</p>
  
                <p>Si dos filósofos intentan tomar el mismo tenedor en un momento dado, estamos ante una <b>condición de carrera.</b></p>
              
                <p>Por otra parte, si todos los filósofos toman el tenedor que está a su derecha entonces todos se quedaran esperando
                infinitamente. Nadie va a ceder su tenedor porque todos están en la misma situación. Esta es la situación que puede abstraerse
                como un <b>interbloqueo.</b></p>
  
              <p>Como podemos hacer para que los filósofos no se mueran de hambre?. Interesante no, el problema en sí
                tiene muchas soluciones pero solo vamos a enunciar una: Un filosofo toma los dos tenedores y se los demás
                hacen una cola alrededor de la mesa para saber cual es el siguiente hasta que todos acaban.</p>

                <h3>¿Cómo atacar el problema de los filósofos?</h3>

                Existen diferentes técnicas algorítmicas para atacar el problema de la cena.

                <ul>
                <li>
                  <b>Round-robin:</b> Es quizás la opción más intuitiva pero menos eficiente. Se implementa un sistema de
                  turnos, y cada filósofo come cuando sea su turno propio. Idealmente, deben tener tiempo limitado por turno,
                  porque de lo contrario, los últimos en esperar morirían de hambre. Puede pensarse como un carrusel.<br><br>
                  <img src="images/LakesideParkCarousel.jpg" width="70%">
                </li>
                <li>
                  <b>Cola de pensadores:</b> Esta solución requiere de algo de detalle matemático y algorítmico. Cuando un
                  filósofo toma un tenedor, espera un tiempo aleatorio para obtener el otro. Si no hay ninguno libre, suelta
                  el primero, se lo entrega al primero de la cola y se va hacia atrás a esperar su turno nuevamente.<br><br>
                  <img src="images/cola_filosofos.png" height="70%">
                </li>
                <li>
                  <b>Árbitro o moderador:</b> Para lograr esta solución se necesita introducir a un actor nuevo, que no
                haga parte activa de la cena. Este actor -llamado árbitro o moderador- debe velar porque en cada escenario
                de n filósofos, sólo haya n-1 sentados en la mesa. De esta manera, se garantiza que al menos uno de los filósofos
                pueda terminar su comida. Cuando el primer filósofo haya terminado, se retirará del recinto e intercambiará lugares
                con quien estaba esperando.<br><br>
                <img src="images/arbitro.png" width="70%">
              </li>
                </ul>

            <h2>Métodos de sincronización y comunicación</h2>
            <p>Existen diversas formas en las que podemos sincronizar y comunicar los hilos, entre ellas tenemos:</p>
            <ul>
              <li><strong>Semáforos:</strong>
                <ul>
                  <li>Un hilo adquiere permiso al entrar a la sección crítica, al finalizar la respectiva sección
                    critica libera el permiso.</li>

                  <li>Está formado por una posición de memoria y dos instrucciones, una para reservarlo (wait o down) y
                    otra para liberarlo (signal o up). A esto se le puede añadir una cola de threads para recordar el
                    orden en que se hicieron la peticiones.</li>

                  <li>Soporte del SO para garantizar la exclusión mutua.</li>

                  <li>Sincronizar dos o más threads o procesos, de modo que su ejecución se realice de forma ordenada y
                    sin conflictos entre ellos.</li>
                  <li>Es una solución con un bajo nivel de abstracción, por lo cual
                    se debe implementar en todo el programa, y puede generar graves
                    problemas de seguridad e implementación.
                  </li>
                </ul><br><br>
                <p><center><img src="images/semaforo.PNG" alt=""></center></p>
                <p>
                  <strong>EJEMPLO:</strong> (Solución posterior)<br><br>
                  Existen uno o más productores y uno o más consumidores, todos almacenan y extraen productos de una
                  misma bodega. El productor produce productos cada vez que puede, y el consumidor los consume cada vez
                  que lo necesita. <br><br>
                  <strong>Problema:</strong> <br><br>
                  ¿Cómo coordinamos a los productores y consumidores, para que los productores no produzcan más ítems de
                  los que se pueden almacenar en el momento, y los consumidores no adquieran más ítems de los que hay
                  disponibles?.<br><br>
                  <strong>Solución:</strong><br>
                  Desde el punto de vista de la programación concurrente la solución a este problema se plantea a través
                  de herramientas de sincronización. La primera solución y la más sencilla es implementar bodegas que
                  sean excluyentes, es decir si un consumidor o productor se encuentra haciendo de la bodega, nadie más
                  pueda hacerlo, indicando este estado con cualquier tipo de señal o aviso, implementado a través de
                  semáforos binarios.<br><br>
                </p>

              </li>
              <li><strong>Exclusión mutua:</strong><br>
                La exclusión mutua es una propiedad del control de concurrencia, cuyo proposito es evitar condiciones de
                carrera,
                es decir, que dos procesos no intenten acceder a un mismo recurso compartido al tiempo (sección
                crítica).
                Por ejemplo, un bloque de memoria.

                <br><br>

                <strong>EJEMPLO:</strong><br><br>

                <center><img src="images/PerroGato.png" height="239px" weight="430px"></center><br><br>

                Se podría realizar una analogía con una breve historia: Alice y Bob comparte un patio,
                Alice tiene un gato y Bob un perro. Las mascotas no se llevan bien, por lo que nunca deberán estar en el
                patio juntas.
                La idea sería mirar el patio, ver si está vacío y, si lo está, liberar a la mascota.
                El cuidado sería que los dos dueños de las mascotas podrían mirar el patio al mismo tiempo.
                La comunicación explícita es requerida para poder coordinarse. El protocolo que se llevaría a cabo
                sería poner a utilizar llamadas para establecer comunicación, pero alguno de los dos puede estar ocupado
                y no responder.
                Es necesario hacer énfasis en que la comunicación debe ser persistente.

                <br><br>

                Dentro de las posibles soluciones para este problema se tienen el uso de las variables compartidas,
                estas son leídas por todos pero escritas solo por un proceso en un instante de tiempo.
                También se podrían utilizar locks, que es una especie de bloqueo al recurso compartido,
                el proceso que posea el lock será el único que puede acceder a la sección crítica.
                La exclusión mutua no puede ser solucionada a través de comunicación transitiva ni interrupciones.

              </li><br>

              <li><strong>Monitores:</strong><br>
                Cada hilo tiene un turno, todos los hilos deben esperar mientras el hilo que tenga el turno esté
                presente en la sección crítica. Aquí los métodos son ejecutados haciendo uso de exclusión mutua
                porque varios hilos de procesos van a querer ingresar en diferentes tiempos pero solo es permitido
                que ingrese uno y así pueda estar activo en el monitor en cierto instante de tiempo. Puesto a que
                es una implementación con un alto nivel de abstracción, ofrece más garantías con respecto a seguridad
                y tolerancia a fallos que otras implementaciones para planificar procesos.
              </li><br>
              <center>
              <div class="row">
                <p><img src="images/monitor_1.PNG" alt=""></p>
                <p><img src="images/monitor_2.PNG" alt=""></p>
              </div>
              </center>

              <li><strong>Mensajes:</strong><br>
                Los hilos se comunican y sincronizan por medio de mensajes, avisandole a los otros hilos cuando puede
                hacer sus respectivas ejecuciones sobre la sección crítica. Un mensaje suele tener dos partes. Una
                "cabecera" y el "cuerpo".
                <br>
                La cabecera usualmente consta de los identificadores de los procesos emisor y receptor el tipo de
                mensaje y la longitud del mensaje.
                <br>
                En el cuerpo se especifica la información adicional que se requiera.
                <br>
                Para el paso de mensajes existen distintos tipos de direccionamiento.
                <ul>
                  <li>Direccionamiento directo: EL proceso emisor especifica cual será el proceso receptor y de igual
                    forma el proceso receptor conoce cual es el proceso emisor del mensaje.</li>
                  <li>Direccionamiento implícito: EL proceso emisor especifica cual será el proceso receptor, pero el
                    proceso receptor no tiene información sobre el proceso emisor.</li>
                  <li>Direccionamiento indirecto: En este caso los mensajes no se envían directamente al receptor, sino
                    que se envían a una estructura de datos denominada buzón o mailbox.
                    <br>
                    En este caso, los procesos que deban entrar en una sección critica deberán leer el buzón para
                    conocer si dicha sección se encuentra habilitad o no.
                  </li>

                </ul>
              </li>
              <li><Strong>Aspectos a tener en cuenta en el paso de mensajes</Strong><br>
                <ul>
                  <li>Buzones: Existen dos casos al trabajar con buzones, en el primero el proceso es el propietario.
                    Para el segundo caso el Sistema Operativo es el responsable del buzón.
                  </li>
                  <li>
                    Sincronización de los mensajes: Es necesario identificar en que secciones criticas es necesario
                    aplicar
                    envio bloqueante y recepción bloqueante o una combinación de estas ya que una mala implementación de
                    paso de mensajes
                    puede terminar en una nueva condición de carrera.
                  </li>
                </ul>
              </li>
            </ul>
            <p>como ejemplo supongamos que en 2 o más bancos se hacen transacciones sobre una misma cuenta,
              si en uno de los bancos (un hilo) cambia el valor de la cuenta mientras en otro banco se realiza una
              transacción sobre la misma
              se daría una condición de carrera, para evitar esto usaremos los múltiples métodos de sincronización:</p>
            <br>
            <p><strong>Ejemplo en java de semaforos: </strong></p>
            <pre class="prettyprint">
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.util.Scanner;
import java.util.concurrent.Semaphore;
import java.util.logging.Level;
import java.util.logging.Logger;

//la clase extiende de thread
public class Banco2 extends Thread{
    static int cuenta=0;
    int Operaciones;
    int [] transaccion;
    final Semaphore available = new Semaphore(1, true);
    boolean[] used = new boolean[1];

    public Banco2(int Operaciones, int[] transaccion) {
        this.Operaciones = Operaciones;
        this.transaccion = transaccion;
    }




    //se sobreescribe el metodo run, que es el que correra al momento de iniciar los hilos
    @Override
    public void run()  {
        try {
        //el hilo adquiere permiso para entrar a la seccion critica
        available.acquire();
        for(int i=0;i< this.Operaciones;i++){
           int temp=cuenta;
                temp=temp+this.transaccion[i];
                cuenta=temp;
            }
        //el hilo libera el permiso
        available.release();
         } catch (InterruptedException ex) {
                Logger.getLogger(Banco2.class.getName()).log(Level.SEVERE, null, ex);
        }


    }
    public static void main(String[] args) throws InterruptedException {
         Scanner sc;

        try {
            //se recibe un archivo con operaciones de entrada y se guardan en arreglos
            sc = new Scanner(new FileReader("C:/archivo3.txt"));
            int A=sc.nextInt();
            int B=sc.nextInt();
            int [] arregloA= new int[A];
            int [] arregloB= new int[B];
            for (int i=0;i< A;i++){
                arregloA[i]=sc.nextInt();
            }
            for (int i=0;i< B;i++){
                arregloB[i]=sc.nextInt();
            }
            Banco2 a=new Banco2(A,arregloA);
            Banco2 b=new Banco2(B,arregloB);
            //se crean los hilos asociados a cada instancia de la clase
            a.start();
            b.start();
            //join de los hilos con el hilo principal de ejecucion
            a.join();
            b.join();
            System.out.println(cuenta);
    }catch (FileNotFoundException ex) {
            Logger.getLogger(Banco2.class.getName()).log(Level.SEVERE, null, ex);
        }
    }

}
</pre>

            <p><strong>Ejemplo en java de monitores: </strong></p>
            <pre class="prettyprint">
  import java.io.FileNotFoundException;
  import java.io.FileReader;
  import java.util.Scanner;
  import java.util.logging.Level;
  import java.util.logging.Logger;

  //igual extiende de la clase hilo
  public class Banco3 extends Thread{
      static int cuenta=0;
      int Operaciones;
      int [] transaccion;
      //usamos turnos para saber cual hilo debe ejecutarse
      static boolean turno = true;

      public Banco3(int Operaciones, int[] transaccion) {
          this.Operaciones = Operaciones;
          this.transaccion = transaccion;
      }

      public synchronized void Operar() throws InterruptedException{
          //mientras el turno no este disponible el hilo espera
          while(!turno) {
              wait();
          }
          //si el turno esta disponible, se toma, poniéndolo como false para el resto
          //de hilos
          turno=false;
          for(int i=0;i< this.Operaciones;i++){
                  int temp=cuenta;
                  temp=temp+this.transaccion[i];
                  cuenta=temp;

          }
          //el turno se libera y se le notifica a los hilos que estaban en espera
          turno=true;
          notifyAll();
      }
      @Override
      public void run()  {
          try {
              Operar();
          } catch (InterruptedException ex) {
              Logger.getLogger(Banco3.class.getName()).log(Level.SEVERE, null, ex);
          }
      }
      public static void main(String[] args) throws InterruptedException {
           Scanner sc;

          try {
              sc = new Scanner(new FileReader("C:/archivo3.txt"));
              int A=sc.nextInt();
              int B=sc.nextInt();
              int [] arregloA= new int[A];
              int [] arregloB= new int[B];
              for (int i=0;i< A;i++){
                  arregloA[i]=sc.nextInt();
              }
              for (int i=0;i< B;i++){
                  arregloB[i]=sc.nextInt();
              }
              Banco3 a=new Banco3(A,arregloA);
              Banco3 b=new Banco3(B,arregloB);
              a.start();
              b.start();
              a.join();
              b.join();
              System.out.println(cuenta);
      }catch (FileNotFoundException ex) {
              Logger.getLogger(Banco3.class.getName()).log(Level.SEVERE, null, ex);
          }
      }

  }
</pre>

            <p><strong>Ejemplo en java de mensajes (es necesario usar el toolkit de akka): </strong></p>
            <pre class="prettyprint">
  import akka.actor.UntypedActor;
  //extiende de un actor de la toolkit de akka
public class BankActor extends UntypedActor{
    static public int cuenta=0;
    //los actores se comunican entre si, se sobreescribe el metodo
    //de onReceive que se ejecuta cuando un hilo recibe mensajes de otro hilo
    @Override
    public void onReceive(Object message) throws Exception {
        if(message instanceof Integer) {
            int a= new Integer((int) message);
            int temp=cuenta;
            temp=temp+a;
            cuenta=temp;
        }else{
            //se tiene en cuenta si el actor no puede comprender el mensaje que se le envio
            unhandled(message);
        }
    }
}


import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;
import java.util.Scanner;


public class Akka {

    public static void main(String[] args) {
        //se instancia un sistema de comunicacion entre los actores
        ActorSystem system=ActorSystem.create("Transacciones");
        //se instancian los dos actores
        ActorRef bankActor = system.actorOf(new Props(BankActor.class), "Transaccion1");
        ActorRef bankActor2 = system.actorOf(new Props(BankActor.class), "Transaccion2");
        Scanner sc2 = new Scanner(System.in);
        int A = sc2.nextInt();
        int B = sc2.nextInt();
        int [] arregloA= new int[A];
        int [] arregloB= new int[B];
        int mayor=0;
        if (A< B){mayor=B;}
        else {mayor=A;}
        for (int i=0;i< mayor;i++){
            //los actores se comunican entre si las transacciones que van haciendo
            if (i< A){
                arregloA[i]=sc2.nextInt();
                bankActor.tell(arregloA[i],null);
            }
            if (i< B){
                arregloB[i]=sc2.nextInt();
            bankActor2.tell(arregloB[i],null);
            }
        }
        system.shutdown(); //cierra la comunicacion
        system.awaitTermination();//join con el hilo principal
        System.out.println(BankActor.cuenta);
    }
}
</pre>

            <ul>
              <li>Solucion del problema Productor - Consumidor</li>
            </ul>
            <p>- Con semaforos</p>
            <pre class="prettyprint">
semaphore fillCount = 0;
semaphore emptyCount = BUFFER_SIZE;

procedure producer() {
  while (true) {
    item = produceItem();
    down(emptyCount);
    putItemIntoBuffer(item);
    up(fillCount);
  }
}

procedure consumer() {
  while (true) {
    down(fillCount);
    item = removeItemFromBuffer();
    up(emptyCount);
    consumeItem(item);
  }
}
</pre>

            <p>- Con monitores</p>
            <pre class="prettyprint">
monitor ProducerConsumer {
  int itemCount;
  condition full;
  condition empty;

  procedure add(item) {
    while (itemCount == BUFFER_SIZE) {
        wait(full);
    }
    putItemIntoBuffer(item);
    itemCount = itemCount + 1;
    if (itemCount == 1) {
        notify(empty);
    }
  }

  rocedure remove() {
      while (itemCount == 0) {
          wait(empty);
      }

      item = removeItemFromBuffer();
      itemCount = itemCount - 1;

      if (itemCount == BUFFER_SIZE - 1) {
          notify(full);
      }
      return item;
  }
}

procedure producer() {
    while (true) {
        item = produceItem()
        ProducerConsumer.add(item)
    }
}

procedure consumer() {
    while (true) {
        item = ProducerConsumer.remove()
        consumeItem(item)
    }
}



</pre>

            <p>Los métodos de sincronización y comunicación se explican de mejor forma mediante el uso del notebook,
              pues los temas se explican con el uso python y C++.</p>

            <a id="notebook"></a>
            <h3><a
                href="http://nbviewer.jupyter.org/url/ferestrepoca.github.io/paradigmas-de-programacion/progconcurrente/concurrente_teoria/notebook/ProgConcurrente.ipynb">Notebook</a>
            </h3>
            <h1>Herramientas de verificación de sistemas concurrentes</h1>
            <h2>Redes de Petri</h2>
            Es un modelo gráfico para describir sistemas concurrentes, se puede ver como un grafo dirigido y bipartido
            donde las dos clases de vértices se denominan lugares y transiciones, se permiten lados paralelos en estas
            redes.
            Al modelar una red de Petri, los lugares representan condiciones, las transiciones representan eventos y la
            presencia de por lo menos una ficha en un lugar indica que la condición se cumple. En una red de Petri (P)
            es un lugar de entrada para la transición T,
            si existe un lado dirigido que va desde el lugar P hasta la transmisión T. De igual forma se define un lugar
            de salida. Si todo lugar de entrada para una transmisión T tiene al menos una ficha, se dirá que T es
            permitida. Una transición permitida que quita una ficha a cada lugar de entrada y agrega una ficha a cada de
            salida se llama descarga.<br>
            Una marca M para una red de Petri esta viva si al empezar en M es posible descargar cualquier transición
            dada a través de una sucesión adicional de descarga, sin importar que la sucesión de descarga ya haya
            sucedido. <br>
            Una marca en una red de Petri es acotada si existe un entero positivo N que tiene la propiedad de que en
            cualquier sucesión de descarga ningún lugar recibe mas de N fichas. Ahora si una marca M esta acotada y en
            cualquier sucesión de descarga ningún lugar recibe mas de una ficha, se dice que M es una marca segura.
            <center><img src="images/petri.png" width="100%" height="400px"></center><br><br>
            <strong><i>Ejemplo en el cual se simula la llegada de material, para luego bifurcarla paralelamente, en dos
                máquinas, y luego unirlos en la salida.</i></strong>
            <h2>CSP (Communicating Sequential Processes)</h2>
            Es una teoría matemática para especificar y verificar patrones de comportamiento como abrazos mortales o
            Livelocks que se dan durante al interacción de objetos concurrentes. Su semántica formal y composicional
            esta completamente ligada con nuestra intuición natural sobre las formas en que las cosas funcionan. Podemos
            ver el modelo como un grupo de componentes organizados en una capa y comunicándose con otra capa de
            componentes a través de canales unidireccionales. Este modelo nació debido a la necesidad de encapsular la
            información de tal manera que esta permanezca correcta, facilitar el diseño y poder detectar fallas antes de
            que estas ocurran. Entre muchas de las ventajas que este modelo brindan esta su semántica sencilla y por
            ende su facilidad de aplicar, sus kernel tan liviano mejorando así el rendimiento de las máquinas y el que
            haya software del tipo de FDR que permita verificar sí el modelo esta correcto o no.
            El enfoque de sincronización que utiliza CSP es el de rende Vuez, que no permite que un proceso escriba si
            al mismo tiempo el otro proceso esta haciendo un leer y viceversa, como estas acciones en teoría se deben
            realizar en paralelo estas deberían ser no bloqueantes.
            <h2> FDR (Failures-Divergence Refinement)</h2>
            Permite la verificación de muchas de las propiedades de sistemas de estados finitos y la investigación de
            sistemas que no pasan ese tipo de verificaciones. Esta basado en la teoría de CSP. Fue desarrollado en la
            universidad de Oxford.
            Su método de probar si una propiedad se cumple es el de probar el refinamiento de un sistema de transición
            que captura la propiedad a través de la máquina candidato.
            También permite verificar el determinismo de una máquina de estados y esto es usado primordialmente para
            corroborar propiedades de seguridad.
            <h2>JCSP (Java communicating sequential processes)</h2>
            Java también desarrolla su propia implementación basada en el álgebra de CSP, orientada a la concurrencia de
            procesos. No se requiere conocimientos avanzados en matemáticas para usar esta herramienta. Al contrario
            permite una simplificación en el diseño que la concurrencia genera.

            JCSP brinda la capacidad a través de bibliotecas completas de desarrollar programas de funcionalidad
            compleja sobre capas de procesos de comunicación. Con esta implementación el modelo CSP aparece soportado
            por las aplicaciones multihilo de Java.
            Los Procesos interactuan solamente a través de la primitivas de sincronización de CSP como channels, CALL
            channels, timers, crews, barriers, buckets o otros modos bien definidos de accesos a objetos pasivos. Dos
            procesos no invocan procesos de si mismos. Estos procesos pueden corren en forma secuencial o paralela.

            Existen también en el mercado aplicaciones que nos permiten verificar computacionalmente modelos
            especificados con CSP y una de las más sobresalientes es FDR.

          </div>
          <div id="aplicaciones">
            <br><br>

            <h1>
              <a id="aplicaciones" class="anchor" href="#aplicaciones" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Aplicaciones del paradigma
            </h1>

           
            
              <p>
                En la cotidianeidad encontramos muchos ejemplos de concurrencia y paralelismo en múltiples procesos con los que interactuamos continuamente. De ellos podemos abstraer características propias que los identifican, así como las partes que los conforman, con el fin de tratar de entender y modelarlos en un entorno virtual.
            
              </p>
            
              <center><img src="images/Aplicaciones-1.jpg" width="80%" height="80%" alt=""></center><br><br>
            
              <p>
                El mundo real contiene actores que ejecutan acciones independientemente, pero que se comunican entre sí al realizarlas. Es por esto que, al modelar el mundo, se deben componer y coordinar muchas ejecuciones paralelas.
              </p>
            
              <ul>
                <li>Redes ferroviarias</li>
                <li>El cuerpo humano y sus diferentes sistemas</li>
                <li>Sistemas de ensamblaje dentro de fábricas</li>
                <li>Equipos de desarrollo de software</li>
              </ul>
            
              <p>Entre muchas otras acciones cotidianas que deben de coordinar distintos procesos para poder ser cumplidas con éxito y funcionar de manera óptima.
              </p>
            
              <p>La concurrencia y el paralelismo nos brindan bastantes herramientas para que la modelación de dichos procesos se realice de manera más apegada a la realidad y, así mismo, para encontrar formas de que estos procesos sean más eficientes al poder separarlos y distribuirlos en pequeños subprocesos que los conformen y se ejecuten en paralelo, es decir, de una manera ligeramente más natural que una ejecución secuencial.
              </p>
            
              <h2>Concurrencia en Software</h2>
            
              <p>La concurrencia y el paralelismo son ampliamente utilizados en distintos enfoques y formas de software, al punto en que constantemente utilizamos programas o escribimos código sin saber que muchos de estos procesos están paralelizados para brindar una mejor experiencia al usuario. Algunos ejemplos de la utilización de concurrencia y paralelismo en ciertos softwares y sistemas son:</p>
            
              <ul style="list-style: none;">
                <li>
                  <h4>Multiprogramming</h4>
                  <p>Dentro de un sistema operativo se pueden ejecutar muchos programas y/o procesos al mismo tiempo y compartiendo la misma memoria. Esto se logra al descomponerlos en subprocesos asignados a distintos núcleos dentro de un procesador.</p><br><br>
                  <center><img src="images/Aplicaciones-Multiprogramming.png" width="80%" height="80%" alt=""></center><br><br>
                  <ul>
                    <li>Descargas </li>
                    <li>Transmisión de datos</li>
                    <li>Lectura de archivos</li>
                    <li>Conexión a internet</li>
                    <li>Manejo de drivers de audio y video</li>
                  </ul>
                </li>
                <li><br><br>
                  <h4>Muchos algoritmos se pueden dividir en partes concurrentes</h4>
                  <div style="display: flex;">
                    <ul>
                      <li>Mergesort </li>
                      <li>Quicksort</li>
                      <li>Sumar una lista sumando fragmentos en paralelo</li>
                      <li>Cálculo de números primos</li>
                      <li>Comprobación de la igualdad de las secuencias de hojas en los árboles</li>
                    </ul>     
                    <img src="images/Aplicaciones-Merge_Paralelo.png" width="40%" height="40%"  style='float: left;' alt="">
                  </div>
                  
                </li>
                <li>
                  <h4>Motores de videojuegos</h4>
                  <p>Los motores que soportan la ejecución de videojuegos deben realizar distintos subprocesos que, orquestados correctamente, componen la experiencia del jugador, como lo son:</p>
                  <center><img src="images/Aplicaciones-Motores.jpg" width="80%" height="80%" alt=""></center>
                  <ul>
                    <li>Game logic</li>
                    <li>Físicas </li>
                    <li>IA</li>
                    <li>Gráficos </li>
                    <li>Inputs del jugador</li>
                    <li>Música y sonido</li>
            
                  </ul>
                </li>
            
                
            
            
              </ul>
              <p>Otros ejemplos puntuales son:</p>
                <ul>
                  <li>Manejo de eventos asincrónicos como la llegada de paquetes de red</li>
                  <li>Ocultar la latencia, mostrando resultados de carga paulatinamente</li>
                  <li>Manejo de redes con múltiples equipos</li>
                  <li>Simulación de eventos complejos</li>
                  <li>Servidores web</li>
                  <li>Sistema multimedia</li>
                  <li>Cálculo numérico</li>
                  <li>Interacción por GUI</li>
                  <li>Sistemas gestores de bases de datos</li>
                  <li>Sistemas Operativos</li>
                  <li>Sistemas de control</li>
                  <li>Simulación</li>
                  <li>Videojuegos</li>
                </ul>
          </div>          
            
            <p>En estos últimos ejemplos, la programación concurrente se utiliza para:<br />
              - Los videojuegos: para la recuperación de claves, la interfaz gráfica y el procesamiento de
              datos recibidos por el servidor para juegos en línea.<br />
              - Servicios web, donde el servidor tendrá que lidiar con muchas solicitudes al mismo tiempo. En este
              contexto,
              se vuelve interesante tener múltiples hilos de ejecución, permitiendo que cada uno de ellos atienda
              una solicitud; de esta manera, habilita la paralelización de la gestión de múltiples tareas. <br />
              - Bases de datos, o ésta, una vez más, tendrá que atender solicitudes al mismo tiempo.<br />
              - Y, finalmente, cualquier interacción con una interfaz gráfica: de hecho, cuando realiza una acción que
              se mostrará en la pantalla, el programa tendrá que continuar mientras que la interfaz gráfica mostrará los
              cambios.<br />
            </p>

            <h2>Aplicaciones Reales</h2>
            <p> Para tomar un ejemplo nos vamos a basar en la <a
                href="https://aws.amazon.com/es/blogs/compute/managing-aws-lambda-function-concurrency/"
                target="_blank">
                documentación oficial de AWS </a> sobre concurrencia dónde nos da un ejemplo muy intuitivo</br>
            </p>
            <center><img src="images/pizza.png" style="margin-left: 30px; margin-bottom: 20px"></center>
            <ul>
              <p>Existe una pizza con propiedades mágicas entre ellas están:</p>
              <li>Tiene un número máximo fijo de porciones, por ejemplo 8.</li>
              <li>Las porciones vuelven a aparecer automáticamente después de ser consumidas.</li>
              <li>Cuando se toma una porción de la pizza, no vuelve a aparecer hasta que se haya consumido por completo.
              </li>
              <li>Una persona puede tomar varias porciones a la vez.</li>
              <li>Se puede pedir fácilmente que se aumente el número de porciones, pero, por lo demás, permanecen fijas
                en
                cualquier momento.</li>
            </ul>
            <p>
              Cuando tenemos un numero menor de personas que intentan comer la pizza dadas las propiedades mágicas de su
              pizza,
              pueden seguir comiendo todo lo que quieran. Pero tenemos dos casos especiales:
            <ul>
              <li>
                Si alguno de ellos toma demasiadas rebanadas a la vez, puede que los demás no reciban la cantidad que
                desean.
              </li>
              <li> Si toman demasiadas rebanadas, también podrían comer demasiado y enfermarse.</li>
            </ul>
            </p>
            <p>
              Una semana en particular, algunos de los amigos tienen más hambre que el resto y toman dos trozos a la vez
              en
              lugar
              de uno solo. Si más de dos de ellos intentan tomar dos trozos a la vez, esto puede provocar una disputa
              por los
              trozos de pizza. Algunos esperarían hambrientos a que las porciones volvieran a aparecer. Podrían pedir
              una
              pizza
              con más trozos, pero volverían a correr el mismo riesgo más tarde si se unen más amigos hambrientos de los
              previstos.
            </p>

            <p> La concurrencia en Lambda funciona de forma similar al modelo de la pizza mágica. Cada cuenta de AWS
              tiene un
              valor
              global de AccountLimit que es fijo en cualquier momento, pero que puede aumentarse fácilmente según sea
              necesario,
              al igual que el recuento de porciones en la pizza.
            </p>
            <p> Al igual que la pizza mágica, cada "porción" de concurrencia solo puede consumirse individualmente de
              una en una.
              Una vez consumida, queda disponible para ser consumida de nuevo.
            </p>

            <p> En general, el paradigma concurrente resulta de mucha utilidad cuando se requiere gestionar y supervisar
                varias actividades distintas al mismo tiempo. En este tipo de problemas la implementación de un paradigma
                más secuencial y determinista sería inviable. Para ilustrar la necesidad real del paradigma concurrente
                se mencionan algunas aplicaciones más:
            </p>
            <ul>
                <li>
                    Aplicación Web: Las aplicaciones Web deben de garantizar una experiencia de calidad para el
                    usuario. ¿Pero que ocurriría si, por ejemplo, frente a algún problema de red temporal la aplicación simplemente
                    se quedara congelada, pasmada, sin permitirnos si quiera interactuar con la intefaz gráfica? Claramente no sería
                    una muy buena experiencia, mucho menos de calidad. Si la aplicación está diseñada de manera secuencial y determinista
                    muy probablemente ocurriría esto, puesto que la aplicación se quedaría esperando una respuesta por parte del servidor, 
                    deteniendo cualquier otra actividad. Afortunadamente esta no es la forma en la que suelen diseñarse. Para mantener
                    la responsividad en este tipo de aplicaciones es necesaria la aplicación del paradigma recurrente. Unos hilos determinados
                    se encargan de la comunicación a través de la red con el servidor, mientras que otros se encargan de la interacción directa
                    con el usuario. De esta forma, la aplicación es capaz de responder (de manera limitada, claro está) a las peticiones del usuario
                    mientras trata de restablecer la comunicación con el servidor, asegurando así una experiencia de mejor calidad.
                </li><br><br>

                <center><img src="images/web-application.png" width="80%" height="80%" alt=""></center><br><br>
 

                <li>
                    Procesador de texto: En este caso no hay comunicación con un servidor, pero un procesador de texto debe encargarse de muchas
                    cosas al mismo tiempo. Un buen procesador de texto debería ser capaz de recibir la entrada del usuario, analizar gramaticalmente
                    lo que recibe y actualizar la interfaz gráfica, todo esto simultaneamente (o lo bastante rápido como parecer que es así). Dicho
                    esto, una solución concurrente surge de forma natural. Similar al caso anterior, habrían hilos especiales encargandose de cada 
                    una de estas actividades distintas.
                </li><br><br>

                <center><img src="images/word-processor.jpeg" width="80%" height="80%" alt=""></center><br><br>

                <li>
                    Sistema operativo: En esta aplicación real es donde más se evidencia la necesidad de este paradigma. Un sistema operativo que funcione
                    de manera secuencial y determinista es impensable. Con la enorme cantidad de actividades que debe de gestionar simultáneamente, como 
                    asignar memoria, atender eventos I/O de distintos dispositivos periféricos (teclado, mouse, monitor, impresora, etc.), ejecutar procesos
                    y encargarse de funciones de red, resulta patente la necesidad de una solución recurrente y que además sea eficiente, puesto que de su
                    correcto funcionamiento depende el funcionamiento de todas las demás aplicaciones que se ejecuten en el sistema.
                </li><br><br>

                <center><img src="images/sistema-operativo.png" width="80%" height="80%" alt=""></center><br><br>





          </div>

          <div id="ventajas">
            <br><br>
            <h1><a class="anchor" href="#ventajas" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Ventajas</h1>

            <ul>
              <li>Permite optimizar el uso de recursos en sistemas mono/multiprocesador.</li>
              <li>Fiable administración de los datos en sistemas con gran información</li>
              <li>Mejor aprovechamiento de la CPU</li>
              <li>Modularidad y reutilización de código</li>
              <li>Desarrollo de software más flexible</li>
              <li>Permite el desarrollo de aplicaciones que no se vean afectadas en tiempo real</li>
              <li>Permite compartir recursos entre tareas lentas y tareas rápidas para que las tareas lentas no retrasen
                mucho a las rápidas.</li>
              <li>Velocidad de ejecución.</li>
              <li>Menores tiempos de respuesta.</li>
              <li>Permite la implementación de programación reactiva</li>
              <li>Controlabilidad</li>
              <li>Disponibilidad de servicios</li>
              <li>Exclusión mutua: nunca más de un proceso está presente en un región crítica</li>
              <li>Sin interbloqueo: ningún proceso se retrasa nunca a la espera de un evento que no puede ocurrir</li>
            </ul>
          </div>
          <div id="desventajas">
            <br><br>
            <h1>Desventajas</h1>
            <ul>
              <li>Seguridad</li>
              <li>Complejidad</li>
              <li>Depuración y pruebas</li>
              <li>Deadlocks y bloqueos</li>
              <li>Consumos de recursos cuando hay excesos de hilos o procesos</li>
              <li>Dificultad de desarrollo.</li>
              <li>Dificultad de verificación.</li>
              <li>En programas con pocas instrucciones en mas lento</li>
              <li>Si se aplica mal puede llevar a resultados erroneos.</li>
            </ul>

          </div>
        </div>

          <div id="lenguajes">
            <br><br>

            <h1>
              <a class="anchor" href="#lenguajes" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Lenguajes
            </h1>

            <ul>
              <li><strong>Elixir</strong></li>
            </ul>
            <center><img src="images/elixir.png" width="150px" height="150px"></center>
            <br>
            Elixir es lenguaje de programación de propósito general, concurrente; este lenguaje es funcional. Además
            está construido sobre la MV de Erlang y aprovecha esto para construir sistemas distribuidos y tolerantes a
            fallos con baja latencia. Es utilizado para construcción de API's y para optimización en el desarrollo web.
            Es utilizado en muchos frameworks como Hedwig, para la implementación de chatbots en distintas redes sociales
            y
            demás. Elixir presenta ejecución por hilos (referida como procesos) en un ambiente en el cuál múltiples
            procesos pueden comunicarse unos con otros vía mensajes.

            <br><br>

            <b>Aplicaciones notables:</b> Changelog, una plataforma de podcasts para desarrolladores. <br><br>

            <ul>
              <li><strong>Ada</strong></li>
            </ul>
            <center><img src="images/ada-coin.jpg" width="150px" height="150px"></center>
            Ada es un lenguaje nacido de un proyecto en los 70s del ejército de los Estados Unidos, el cual tenía como
            principal requisito la seguridad, es decir, se debía tener un lenguaje con nula cantidad de errores. El
            lenguaje es usado de forma amplia en la industria de las infraestructuras de riesgo grande, como lo es
            sistemas de aviones, trenes, tanques y misiles. Es fuertemente tipado, uno de los más tipados, debido a la
            necesidad explicita de minimizar los errores. Ha tenido relativamente pocas actualizaciones. Es uno de los
            pioneros en programación orientado a objetos, lenguaje multipropósito. Sincroniza las tareas por rendez
            vous.

            <br><br>

            <b>Aplicaciones notables:</b> Sistemas de planeación aérea y naval. <br><br>


            <ul>
              <li><strong>Rust</strong></li>
            </ul>
            <center><img src="images/rust.png" width="150px" height="150px"></center>
            Rust es un lenguaje de programación compilado, de propósito general y multiparadigma desarrollado por
            Mozilla y ha sido diseñado para ser ‘un lenguaje seguro, concurrente y práctico’. Rust se enfoca
            principalmente en seguridad, velocidad y concurrencia. Una de sus principales características es que es
            posible arreglar bugs en tiempo de ejecución. Usado en desarrollo web y embebido. <br><br>

            <b>Aplicaciones notables:</b> Partes del kernel de Linux, cuya escritura es soportada desde octubre de 2022. <br><br>

            <ul>
              <li><strong>Erlang</strong></li>
            </ul>
            <center><img src="images/erlang.png" width="150px" height="150px"></center>
            Erlang es un lenguaje de programación funcional de alto nivel, diseñado para escribir aplicaciones
            concurrentes y distribuidas de funcionamiento ininterrumpido. Erlang usa procesos concurrentes para
            estructurar la aplicación. Estos procesos no comparten memoria y se comunican de forma asincrónica mediante
            el paso de mensajes. Utilizado en telecomunicaciones, e-commerce y mensajería instantánea.

            <br><br>

            <b>Aplicaciones notables:</b> Lógica de negocio de aplicaciones como WhatsApp. <br><br>

            <ul>
              <li><strong>GO</strong></li>
            </ul>
            <center><img src="images/go.png" width="150px" height="150px"></center>
            GO Es un lenguaje de programación compilado, concurrente, imperativo, estructurado, no orientado a objetos
            con recolector de basura, soportado en diferentes tipos de sistemas. La concurrencia en Go es diferente a
            los criterios de programación basados en bloqueos como pthreads. Es fácil de aprender debido a su similitud
            con los lenguajes más usados, es implementado en modelos de negocio y manejo de servidores.

            <br><br>

            <b>Aplicaciones notables:</b> El código backend de Uber.<br><br>

            <ul>
              <li><strong>Haskell</strong></li>
            </ul>
            <center><img src="images/haskell.png" width="150px" height="150px"></center>
            Haskell es un lenguaje polimórficamente tipificado, perezoso, puramente funcional, muy diferente a la
            mayoría de los otros lenguajes de programación. La concurrencia es "ligera", lo que significa que tanto la
            creación de hilos como los gastos generales de cambio de contexto son extremadamente bajos. La programación
            de los hilos de Haskell se hace internamente y no hace uso de ningún paquete de hilos suministrado por el
            sistema operativo.

            <br><br>

            <b>Aplicaciones notables:</b> Análisis de sintaxis en código alojado en GitHub <br><br>

            <ul>
              <li><strong>Crystal</strong></li>
            </ul>
            <center><img src="images/crystal.png" width="150px" height="150px"></center>
            Crystal es uno de los nuevos lenguajes en la escena. Aunque no tan conocido como Rust, Elixir o Julia, tiene
            mucho que ofrecer. Iniciò en 2012, y según describen sus creadores, sus características principales son:
            <br /><br />
            - Sintaxis similar a Ruby<br />
            - Estáticamente tipado<br />
            - Compilado<br />
            - Self-hosted (Crystal está escrito en… crystal)

            <br /><br />
            Crystal viene con una primitiva de concurrencia llamada fibras, que son básicamente una versión más ligera
            de hilos.
            Las otras primitivas de concurrencia son canales. Si ha hecho algo de Golang, esta es básicamente la misma
            idea.

            <br><br>

            <b>Aplicaciones notables:</b> Servicios web de compañías como Errordeck, GigSmart, Appmonitor, etc. <br><br>

            <ul>
              <li><strong>Java</strong></li>
            </ul>
            <center><img src="images/java.png" width="200px" height="150px"></center>

            Java es un lenguaje de programación orientado a objetos creado en 1991 y publicado en 1995 por Sun
            Microsystem (adquirida por Oracle en 2010), con la intención de que los programadores escribieran el código
            solo una y lo ejecutarán en cualquier dispositivo. Java permite realizar concurrencia con la librería
            threads. Además de que cuenta con otras librerías que implementan métodos de planificación y control de
            procesos
            (variables atómicas, semáforos, entre otros) traídos del paquete concurrent.
            <div class="mt-4">
              <p>Es altamente recomendable de utilizar hilos con estos lenguajes. En cualquier caso, cuando, un lenguaje
                permite de hacer programación concurrente, debe usarlo. Además, cuando uses estos lenguajes, a menudo
                usarás hilos sin siquiera saberlo. De hecho, hay muchas funciones incluidas en los lenguajes que crean
                un
                hilo sin preguntarle al programador.</p>
            </div>


            <b>Aplicaciones notables:</b> Innumerables. Desde servicios web backend mediante Spring Boot hasta desarrollo
            de videojuegos con LWJGL, la librería usada para escribir Minecraft.<br><br>

            <ul>
              <li><strong>python</strong></li>
            </ul>
            <center><img src="images/python.png" width="96px" height="96px"></center>

            Python es el lenguaje más utilizado a nivel mundial (según revista IEEE), es un lenguaje de sintaxis simple
            y cuyas
            aplicaciones cubren una gran cantidad de áreas del conocimiento como lo son inteligencia artificial, ciencia
            de datos,
            entre otras. En cuanto a programación concurrente, cuenta con varias librerías para la implementación de
            esta y su respectivo
            control, como lo son la librería "Thread" y "Multiprocessing", que provee de herramientas como semáforos,
            monitores, entre otros.
            Específicamente la librería "Thread" incluye una interfaz de alto nivel orientada a objetos para trabajar
            con concurrencia desde
            Python. Los objetos Thread se ejecutan al mismo tiempo dentro del mismo proceso y comparten memoria.
              
            <br><br>

            <b>Aplicaciones notables:</b> El backend de Instagram. <br><br>

            <ul>
              <li><strong>C</strong></li>
            </ul>
            <center><img src="images/c.jpg" width="180px" height="96px"></center>
            C es uno de los lenguajes más rápidos que existen puesto a que es un lenguaje compilado, es altamente usado
            en el diseño y desarrollo
            de los sistemas operativos que hoy en día se usan, además de que facilita el uso de memoria dinámica y
            muchas otras características.
            En cuanto a programación concurrente, usa la librería pthread.h para la creación de hlos y métodos de
            control muy básicos como la implementación
            de un semáforo.

            <br><br>

            <b>Aplicaciones notables:</b> El kernel de Linux y otros lenguajes como Python y C++. <br><br>

            <ul>
              <li><strong>C++</strong></li>
            </ul>
            <center><img src="images/cpp.png" width="96px" height="96px"></center>
            <br>
            Fue diseñado a mediados de los años 80 por el danés Bjarne Stroustrup. Su intención fue la de extender el
            lenguaje de programación C
            para que tuviese los mecanismos necesarios para manipular objetos. Por lo tanto C++ contiene los paradigmas
            de la programación estructurada
            y orientada a objetos. Se puede usar una librería thread que es básicamente una sección de código
            independiente que el procesador puede ejecutar
            de forma concurrente junto a otros threads o hilos de ejecución.

            <br><br>

            <b>Aplicaciones notables:</b> Motores gráficos como Source de Valve, usado en videojuegos como Half-Life
            y Counter-Strike.<br><br>

          </div>
          <div id="ejemplos">
            <br><br>

            <h1>
              <a class="anchor" href="#ejemplos" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Lenguajes ejemplos
            </h1>

            <ul>
              <li>Ejemplo en <strong>python</strong>: Este es un pequeño ejemplo con el fin de ilustrar como podemos
                lanzar un hilo en python</li>
            </ul>

            <div class="highlight highlight-source-python">
              <pre><span class="pl-k">from</span> threading <span class="pl-k">import</span> Thread
<span class="pl-k">import</span> time

<span class="pl-k">def</span> <span class="pl-en">say_hello</span>(<span class="pl-smi">name</span>):
    <span class="pl-c1">print</span> (name, <span class="pl-s"><span class="pl-pds">"</span>Hola<span class="pl-pds">"</span></span>)

t <span class="pl-k">=</span> Thread(<span class="pl-v">target</span><span class="pl-k">=</span>say_hello, <span class="pl-v">args</span><span class="pl-k">=</span>(<span class="pl-s"><span class="pl-pds">"</span>world<span class="pl-pds">"</span></span>,))
t.start()
t.join()</pre>
            </div>

            <p><strong>Ejecucion:</strong> python archivo.py</p>

            <blockquote>
              <p>('world', 'Hola')</p>
            </blockquote>

            <ul>
              <li>Ejemplo en <em>GO</em>: En este ejemplo podemos visualizar que los hilos no se ejecutan en el orden
                ascedente si no esto lo decide el scheduler del sistema operativo</li>
            </ul>

            <div class="highlight highlight-source-go">
              <pre><span class="pl-k">package</span> main

<span class="pl-k">import</span> (
    <span class="pl-s"><span class="pl-pds">"</span>fmt<span class="pl-pds">"</span></span>
    <span class="pl-s"><span class="pl-pds">"</span>time<span class="pl-pds">"</span></span>
)

<span class="pl-k">const</span> <span class="pl-v">FINAL</span> = <span class="pl-c1">100</span> * time.<span class="pl-smi">Millisecond</span>

<span class="pl-k">func</span> <span class="pl-en">saluda</span>(<span class="pl-v">i</span> <span class="pl-v">int</span>) {
    time.<span class="pl-c1">Sleep</span>(<span class="pl-c1">10</span> * time.<span class="pl-c1">Duration</span>(i%<span class="pl-c1">5</span>) * time.<span class="pl-smi">Millisecond</span> )
    fmt.<span class="pl-c1">Println</span>(<span class="pl-s"><span class="pl-pds">"</span>Hola a todos<span class="pl-pds">"</span></span>, i)
}

<span class="pl-k">func</span> <span class="pl-en">main</span>() {
    <span class="pl-k">for</span> <span class="pl-smi">i</span> <span class="pl-k">:=</span> <span class="pl-c1">1</span>; i &lt;= <span class="pl-c1">6</span>; i++ {
        <span class="pl-c">// Lanzamos nuestro hilo solo anteponiendo la palabra go a la funcion</span>
        <span class="pl-k">go</span> <span class="pl-c1">saluda</span>(i)
    }
    time.<span class="pl-c1">Sleep</span>(FINAL)
}</pre>
            </div>

            <p><strong>Ejecucion:</strong> go run archivo.go</p>

            <blockquote>
              <p>Hola a todos 5</p>

              <p>Hola a todos 6</p>

              <p>Hola a todos 1</p>

              <p>Hola a todos 2</p>

              <p>Hola a todos 3</p>

              <p>Hola a todos 4</p>
            </blockquote>

            <ul>
              <li>Ejemplos semaforo en <strong>C</strong>: El siguiente codigo fuente solo sirve sistemas operativos
                basado en unix.</li>
            </ul>

            <div class="highlight highlight-source-c">
              <pre>#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>stdlib.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>stdio.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>pthread.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>unistd.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>sys/types.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>fcntl.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>sys/stat.h<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>semaphore.h<span class="pl-pds">&gt;</span></span>

#<span class="pl-k">define</span> <span class="pl-en">NUMHILOS</span> <span class="pl-c1">5</span>

<span class="pl-c1">sem_t</span> *semaforo;
<span class="pl-k">int</span> error, i, parametro, a;
<span class="pl-k">char</span> t;
<span class="pl-k">void</span> *z;

<span class="pl-k">void</span> *<span class="pl-en">fun</span>(<span class="pl-k">void</span> *ap )
{
    <span class="pl-c1">sem_t</span> *sem = ap;
    <span class="pl-k">char</span> t;
    <span class="pl-c1">sem_wait</span>( sem ); <span class="pl-c">// Bloqueamos seccion critica</span>
    <span class="pl-c1">printf</span>( <span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\n</span> Hilo ENTRO a seccion critica<span class="pl-pds">"</span></span> );
    <span class="pl-c1">fflush</span>( stdout );
    <span class="pl-c1">sleep</span>( <span class="pl-c1">1</span> );
    <span class="pl-c1">printf</span>( <span class="pl-s"><span class="pl-pds">"</span><span class="pl-cce">\n</span> Hilo SALIO a seccion critica<span class="pl-cce">\n\n</span><span class="pl-pds">"</span></span> );
    <span class="pl-c1">fflush</span>( stdout );
    <span class="pl-c1">sem_post</span>( sem ); <span class="pl-c">// Desbloqueamos seccion critica</span>
}

<span class="pl-k">int</span> <span class="pl-en">main</span>()
{
    <span class="pl-c">// Creamos nuestro semaforo</span>
    semaforo = <span class="pl-c1">sem_open</span>( <span class="pl-s"><span class="pl-pds">"</span>sema<span class="pl-pds">"</span></span>, O_CREAT, <span class="pl-c1">0666</span>, <span class="pl-c1">1</span> );

    <span class="pl-c">// Declaramos el descritor de los hilos</span>
    <span class="pl-c1">pthread_t</span> hilos[NUMHILOS];

    <span class="pl-c">// Creamos nuestros hilos</span>
    <span class="pl-k">for</span>( i = <span class="pl-c1">0</span>; i &lt; NUMHILOS; i++ )
        <span class="pl-c1">pthread_create</span>( &amp;hilos[i], <span class="pl-c1">NULL</span>, (<span class="pl-k">void</span> *)fun, semaforo );

    <span class="pl-c">// Esperamos a que nuestro hilos de ejecutan antes de terminar el programa</span>
    <span class="pl-k">for</span>( i = <span class="pl-c1">0</span>; i &lt; NUMHILOS; i++ )
        <span class="pl-c1">pthread_join</span>( hilos[i], (<span class="pl-k">void</span> *)&amp;z );

    <span class="pl-c">// Destruimos nuestro semaforo</span>
    <span class="pl-c1">sem_unlink</span>( <span class="pl-s"><span class="pl-pds">"</span>sema<span class="pl-pds">"</span></span> );
    <span class="pl-c1">sem_close</span>( semaforo );
    <span class="pl-k">return</span> <span class="pl-c1">0</span>;
}</pre>
            </div>

            <p>Compilamos: <strong>gcc semaforo.c -o semaforo -pthread</strong></p>

            <p>Ejecutamos: <strong>./semaforo</strong></p>

            <blockquote>
              <p>Hilo ENTRO a sección critica</p>

              <p>Hilo SALIO a sección critica</p>

              <p>Hilo ENTRO a sección critica</p>

              <p>Hilo SALIO a sección critica</p>

              <p>Hilo ENTRO a sección critica</p>

              <p>Hilo SALIO a sección critica</p>
            </blockquote>

            <ul>
              <li>Ejemplo en <strong>C++</strong>: Calculamos el numero pi con 4 hilos con la ayuda de <a
                  href="https://es.wikipedia.org/wiki/Serie_de_Leibniz">Serie de Leibniz</a> </li>
            </ul>

            <div class="highlight highlight-source-c++">
              <pre>#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>iostream<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>thread<span class="pl-pds">&gt;</span></span>
#<span class="pl-k">include</span> <span class="pl-s"><span class="pl-pds">&lt;</span>vector<span class="pl-pds">&gt;</span></span>

<span class="pl-k">using</span> <span class="pl-k">namespace</span> <span class="pl-en">std</span><span class="pl-k">;</span>
vector&lt;<span class="pl-k">double</span>&gt; <span class="pl-en">valorCal</span>( <span class="pl-c1">4</span>, <span class="pl-c1">0.0</span> ), limites;

<span class="pl-k">void</span> <span class="pl-en">calcularIntervalo</span> (<span class="pl-k">int</span> index)
{
    <span class="pl-k">for</span> (<span class="pl-k">int</span> i = limites[<span class="pl-c1">index</span>]; i &lt; limites[<span class="pl-c1">index</span>+<span class="pl-c1">1</span>]; i++)
        <span class="pl-k">if</span> (i % <span class="pl-c1">2</span> == <span class="pl-c1">0</span>)
            valorCal[<span class="pl-c1">index</span>] += <span class="pl-c1">1.0</span>/(<span class="pl-c1">2</span>*i+<span class="pl-c1">1</span>);
        <span class="pl-k">else</span>
            valorCal[<span class="pl-c1">index</span>] -= <span class="pl-c1">1.0</span>/(<span class="pl-c1">2</span>*i+<span class="pl-c1">1</span>);
}

<span class="pl-k">int</span> <span class="pl-en">main</span>()
{
    <span class="pl-c">// Creamos nuestro limites</span>
    <span class="pl-k">int</span> numeroSerie = <span class="pl-c1">1000000000</span>;
    limites.<span class="pl-c1">push_back</span>( <span class="pl-c1">0</span> );
    limites.<span class="pl-c1">push_back</span>( numeroSerie/<span class="pl-c1">4</span> );
    limites.<span class="pl-c1">push_back</span>( numeroSerie/<span class="pl-c1">2</span> );
    limites.<span class="pl-c1">push_back</span>( <span class="pl-c1">3</span>*(numeroSerie/<span class="pl-c1">4</span>) );
    limites.<span class="pl-c1">push_back</span>( numeroSerie );

    <span class="pl-c">// Creamos a hilos</span>
    thread hilos[<span class="pl-c1">4</span>];

    <span class="pl-c">// Inicializamos nuestros hilos</span>
    <span class="pl-k">for</span> (<span class="pl-k">int</span> i = <span class="pl-c1">0</span>; i &lt; <span class="pl-c1">4</span>; i++)
        hilos[i] = <span class="pl-c1">thread</span>( calcularIntervalo, i );

    <span class="pl-c">// Esperemos a que nuestros hilos terminen</span>
    <span class="pl-k">for</span> (<span class="pl-k">int</span> i = <span class="pl-c1">0</span>; i &lt; <span class="pl-c1">4</span>; i++)
        hilos[i].<span class="pl-c1">join</span>();

    <span class="pl-c">// Calculamos nuestra respuesta</span>
    <span class="pl-k">double</span> answer = <span class="pl-c1">0</span>;
    <span class="pl-k">for</span> (<span class="pl-k">int</span> i = <span class="pl-c1">0</span>; i &lt; <span class="pl-c1">4</span>; i++)
        answer += valorCal[i];
    answer *= <span class="pl-c1">4</span>;
    <span class="pl-c1">printf</span>( <span class="pl-s"><span class="pl-pds">"</span>EL valor de pi es:<span class="pl-cce">\t</span><span class="pl-c1">%.20f</span><span class="pl-cce">\n</span><span class="pl-pds">"</span></span>, answer );
    <span class="pl-k">return</span> <span class="pl-c1">0</span>;
}</pre>
            </div>

            <p>Compilar: <strong>g++ pi.cpp -o pi -std=c++11 -pthread</strong></p>

            <p>Ejecutar: <strong>./pi</strong></p>

            <blockquote>
              <p>EL valor de pi es: 3.14159265258921038821</p>
            </blockquote>

            <ul>
              <li>Ejemplo en <strong>Java</strong>:</li>
            </ul>
            <p>Un grupo de personas trata de ir de una isla(Oahu) a la otra(Molokai) con un solo bote.</p>
            <p><img src="https://s1-ssl.dmcdn.net/hjNxe/x240-XWg.jpg" alt=""></p>

            <p>Reglas:</p>
            <ul>
              <li>Cada persona es un hilo.</li>
              <li>La persona puede ser un adulto o un niño.</li>
              <li>Pueden ir dos niños en el bote o solo un adulto.</li>
              <li>El bote necesita como mínimo un piloto./li>
              <li>las personas solo se pueden comunicar con los que estén en la misma isla.</li>
              <li>Siempre hay mínimo dos niños.</li>
            </ul>

            <p>El principal objetivo del ejemplo es mostrar la sincronización de los hilos, la solución al problema
              consiste en llevar dos niños
              a Molokai, hacer que uno se devuelva con el bote, subir un adulto en oahu, cuando este llegue a Molokai se
              devolverá el otro niño
              que estaba ahí, y en Oahu se volverán a subir dos niños, este proceso se repetirá hasta que todas las
              personas estén en Oahu,
              hay que tener en cuenta que no hay algo como unidad principal que controle cuando pasará cada persona,
              cada hilo deberá saber cuando
              ejecutar sus instrucciones dependiendo de la sincronización con los otros</p>
            <pre class="prettyprint">

import java.util.concurrent.Semaphore;

//extiende de thread y sobreescribe run sin nada
public class Persona extends Thread{

	int Tamano;
	String ubicacion;
	static String boatUbication="Oahu";
	public static String getBoatUbication() {
		return boatUbication;
	}

	public static void setBoatUbication(String boatUbication) {
		Persona.boatUbication = boatUbication;
	}

	public Persona(int tamano, String ubicacion) {
		super();
		this.Tamano = tamano;
		this.ubicacion = ubicacion;
	}

	@Override
    public void run() {

	}



}



import java.util.logging.Level;
import java.util.logging.Logger;

//extiende de persona
public class Adult extends Persona {
	public Adult() {
		super(2, "Oahu");
	}
	//sobreescribe run
	@Override
    public void run() {
		//mientras no hayan pasado todas las personas
		while(Boat.ContMolokai < Boat.ContTotalPersonas){
		 try {
			 //semaforo encargado de que un niño y adulto no luchen por el bote
			 Boat.classExclus.acquire();
             if (this.ubicacion.equals("Oahu") && boatUbication.equals(this.ubicacion) && Boat.ContChildBack%2!=0 && Boat.ContAdultOahu != 0){
            	 //si ve que puede pasar lo hace, adquiere las dos posiciones del bote
            	 Boat.available.acquire();
            	 Boat.available.acquire();
            	 Boat.bg.AdultRowToMolokai();
            	 this.ubicacion="Molokai";
            	 boatUbication="Molokai";
            	 Boat.ContMolokai++;
           		 Boat.ContOahu--;
           		 Boat.ContAdultOahu--;
           		 //al llegar libera las dos posiciones del bote
            	 Boat.available.release();
            	 Boat.available.release();
             }

             Boat.classExclus.release();
         } catch (InterruptedException ex) {
             Logger.getLogger(Child.class.getName()).log(Level.SEVERE, null, ex);
         }
	}
	}
}


import java.util.concurrent.Semaphore;
import java.util.logging.Level;
import java.util.logging.Logger;

//parecida a Adult
public class Child extends Persona {
	public Child() {
		super(1, "Oahu");
	}
	@Override
    public void run() {
		while(Boat.ContMolokai < Boat.ContTotalPersonas ){
		 try {
			 Boat.classExclus.acquire();
             if (this.ubicacion.equals("Oahu") && boatUbication.equals(this.ubicacion) && (Boat.ContChildBack%2==0 || Boat.ContAdultOahu == 0) ){
            	 //a diferencia del adulto el niño solo adquiere una posicion del bote
            	 Boat.available.acquire();
            	 Boat.UbicacionDispon--;
            	 if (Boat.UbicacionDispon==1) Boat.bg.ChildRowToMolokai();
            	 this.ubicacion="Molokai";
            	 Boat.ContMolokai++;
            	 Boat.ContOahu--;
            	 if(Boat.UbicacionDispon==0){
            		 Boat.bg.ChildRideToMolokai();
            		 boatUbication="Molokai";
            		 Boat.UbicacionDispon=2;
            	 }
            	 Boat.available.release();
             }
             //parte de la seccion critica encargada de que el niño regrese desde Molokai a Oahu
            	 if (this.ubicacion.equals("Molokai") && boatUbication.equals(this.ubicacion) && (Boat.ContMolokai < Boat.ContTotalPersonas ) ){
            		 //para evitar que se regresen dos niños el niño adquiere las dos posiciones
            		 //del bote
            		 Boat.available.acquire();
            		 Boat.available.acquire();
            		 Boat.bg.ChildRowToOahu();
                	 this.ubicacion="Oahu";
                	 boatUbication="Oahu";
                	 Boat.ContMolokai--;
                	 Boat.ContOahu++;
                	 Boat.ContChildBack++;
                	 //llega y libera las dos posiciones
                	 Boat.available.release();
                	 Boat.available.release();
            	 }

            	 Boat.classExclus.release();
         } catch (InterruptedException ex) {
             Logger.getLogger(Child.class.getName()).log(Level.SEVERE, null, ex);
         }

		}
	}

}



import java.util.Scanner;
import java.util.concurrent.Semaphore;
import java.util.LinkedList;

public class Boat {
	//se instancian los dos semaforos
	public static Semaphore available = new Semaphore(2, true);
	public static Semaphore classExclus = new Semaphore(1, true);
	static Scanner sc = new Scanner(System.in);
	//contadores para la comunicacion
	static int childrenTot=0;
	static int adultTot=0;
	static int ContChilds=0;
	static int ContAdults=0;
	static int ContTotalPersonas=0;
	static int ContOahu=0;
	static int ContMolokai=0;
	static int ContAdultOahu=0;
	static int UbicacionDispon=2;
	static int ContChildBack=0;

	//arreglo de personas
	static LinkedList<Child> ChildList = new LinkedList<Child>();
	static LinkedList<Adult> AdultList = new LinkedList<Adult>();
	static BoatGrader bg= new BoatGrader();

	//se crean los hilos
	static public void begin(){
		for(Child element : ChildList){
			element.start();


		}
		for(Adult element : AdultList){
			element.start();

		}
		//al terminar los hilos hacen join con el hilo principal
		for(Child element : ChildList){
			try {
				element.join();
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}
		for(Adult element : AdultList){
			try {
				element.join();
			} catch (InterruptedException e) {
				// TODO Auto-generated catch block
				e.printStackTrace();
			}
		}



	}

	public static void main(String args[]) {
		//entradas del programa
		while (childrenTot< 2){
			System.out.println("Introduzca el numero de niños (mayor a 1): ");
			childrenTot=sc.nextInt();
		}
		System.out.println("Introduzca el numero de adultos: ");
		adultTot=sc.nextInt();
	    for (int i=0;i< childrenTot;i++){
	    	ChildList.add(new Child());
	    	ContChilds++;
	    }
	    for (int i=0;i< adultTot;i++){
	    	AdultList.add(new Adult());
	    	ContAdults++;
	    }
	    ContTotalPersonas=ContChilds+ContAdults;
	    ContAdultOahu=ContAdults;
		ContOahu=ContTotalPersonas;

	    Boat.begin();
	    System.out.println("llegaron "+ContMolokai+" personas");
	}
}
</pre>
            <p>ejecución:</p>
            <pre class="prettyprint">
  Introduzca el numero de niños (mayor a 1):
  3
  Introduzca el numero de adultos:
  5
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  **Child rowing to Oahu.
  **Adult rowing to Molokai.
  **Child rowing to Oahu.
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  **Child rowing to Oahu.
  **Adult rowing to Molokai.
  **Child rowing to Oahu.
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  **Child rowing to Oahu.
  **Adult rowing to Molokai.
  **Child rowing to Oahu.
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  **Child rowing to Oahu.
  **Adult rowing to Molokai.
  **Child rowing to Oahu.
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  **Child rowing to Oahu.
  **Adult rowing to Molokai.
  **Child rowing to Oahu.
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  **Child rowing to Oahu.
  **Child rowing to Molokai.
  **Child arrived on Molokai as a passenger.
  llegaron 8 personas


</pre>
            <ul>
              <li>Ejemplo en <strong>Go</strong>:</li>
            </ul>
            <pre class="prettyprint">
  package main
  import(
  	"fmt"
  	"time"
  )
  func main() {
      fmt.Println("iniciando")
      go printForward()
      go printBackwards()
  	time.Sleep(time.Second * 5)
      fmt.Println("terminando")
  }
  func printForward() {
      for i := 0; i < 10; i++ {
          fmt.Println(i)
          time.Sleep(time.Millisecond)
      }
  }
  func printBackwards() {
      for i := 10; i <= 20; i++ {
          fmt.Println(i)
          time.Sleep(time.Millisecond)
      }
  }
</pre>
            <p>En Go tenemos rutinas que tienen su propio stack, aunque estos no son hilos como tal, pero si se pueden
              aprovechar de esta forma</p>
            <pre class="prettyprint">
package main
import(
	"fmt"
	"time"
)
func main() {
    c := make(chan string)
    go echo(c)
    c < - "Hola"
    mensaje := < - c
    fmt.Println(mensaje)
}

func echo(c chan string) {
    msg := < - c
    time.Sleep(time.Second * 1)
    c < - fmt.Sprintf("Mensaje recibido: %s", msg)
}

salida= Mensaje recibido:Hola
</pre>

            <p>En Go tenemos el Select es como un switch, pero que espera mensajes en canales.
              Su finalidad es comunicar, no comparar valores. </p>
            <pre class="prettyprint">
package main
import(
  "fmt"
  "time"
)
func main() {
    process1 := processExpensiveTransaction()
    process2 := processExpensiveTransaction()
    for i := 0; i < 2; i++ {
        select {
            case msg1 := <- process1:
                fmt.Println("Proceso 1 termino con status ", msg1)
            case msg2 := <- process2:
                fmt.Println("Proceso 2 termino con status ", msg2)
        }
    }
}

func processExpensiveTransaction() chan string {
    c := make(chan string)
    go func() {
        time.Sleep(time.Duration(rand.Intn(6)) * time.Second)
        c <- "ok"
    } ()
    return c
}
</pre>
            <ul>
              <li>Otro Ejemplo en <strong>Go</strong>:</li>
            </ul>
            <p>
              En este ejemplo vamos a optimizar una aplicación que realiza peticiones http, haciendo uso de
              concurrencia,
              el siguiente código es la aplicación implementada de manera secuencial:
            </p>
            <pre class="prettyprint">
package main
import (
	"fmt"
	"log"
	"net/http"
	"os"
)
func sendRequest(url string){
  res, err := http.Get(url)
  if err != nil{
    panic(err)
  }
  fmt.Printf("Estado: %d URL: %s\n", res.StatusCode,url)
}

func main() {
	if len(os.Args) < 2 {
		log.Fatalln("Uso: go run main.go url1 url2 .. urln")
	}

	for _, url := range os.Args[1:] {
		sendRequest("https://" + url)
	}
}
</pre>
            <p>
              Para hacer uso del programa, usamos el siguiente comando:
            <pre class="prettyprint">
    go run main.go url1 url2 .. urln
  </pre>
            Donde url1 a urln se reemplazan por urls a las cuales queremos hacer la petición Get.
            Los resultados de esto deberían ser los siguientes, en el caso de haber usado las urls de google, youtube y
            facebook:
            </p>
            <pre class="prettyprint">
Estado: 200 URL: https://facebook.com
Estado: 200 URL: https://youtube.com
Estado: 200 URL: https://google.com
</pre>
            <p>
              Para medir el tiempo de ejecución se debe usar el siguiente comando:
            </p>
            <p>
              Para Windows:
            <pre class="prettyprint">
    Measure-Command {go run main.go url1 url2 .. urln}
    </pre>
            Para Linux:
            <pre class="prettyprint">
    time go run main.go url1 url2 .. urln
    </pre>
            Este tiempo de ejecución es importante para comparar el antes y el después de usar concurrencia. Haciendo
            uso del comando de Windows, obtuvimos como resultado:
            </p>
            <pre class="prettyprint">
Days              : 0
Hours             : 0
Minutes           : 0
Seconds           : 1
Milliseconds      : 970
Ticks             : 19702343
TotalDays         : 2,28036377314815E-05
TotalHours        : 0,000547287305555556
TotalMinutes      : 0,0328372383333333
TotalSeconds      : 1,9702343
TotalMilliseconds : 1970,2343
</pre>
            <p>
              Actualmente nuestra aplicación funciona de manera síncrona, lo cual ralentiza su procesamiento,
              debido a que tiene que esperar que cada petición termine para poder realizar la siguiente.
              Ahora vamos a modificar este programa inicial para usar concurrencia y optimizar nuestra aplicación:
            </p>
            <pre class="prettyprint">
  package main
  import (
    "fmt"
    "log"
    "net/http"
    "os"
  )
  func sendRequest(url string){
    res, err := http.Get(url)
    if err != nil{
      panic(err)
    }
    fmt.Printf("Estado: %d URL: %s\n", res.StatusCode,url)
  }
  
  func main() {
    if len(os.Args) < 2 {
      log.Fatalln("Uso: go run main.go url1 url2 .. urln")
    }
  
    for _, url := range os.Args[1:] {
      go sendRequest("https://" + url)
    }
  }
</pre>
            <p>
              Con solo agregar la palabra go, hacemos que cada consulta se ejecute en goroutines separadas
              y si ejecutamos el comando de Benchmark anteriormente mencionado vamos a observar que
              el tiempo de ejecucion es mucho menor:
            </p>
            <pre class="prettyprint">
Days              : 0
Hours             : 0
Minutes           : 0
Seconds           : 0
Milliseconds      : 832
Ticks             : 8328442
TotalDays         : 9,63940046296296E-06
TotalHours        : 0,000231345611111111
TotalMinutes      : 0,0138807366666667
TotalSeconds      : 0,8328442
TotalMilliseconds : 832,8442
</pre>
            <p>
              Pero nos vamos a encontrar con un problema: no se imprimen los resultados de las goroutines
              en consola.
              Para corregir esto vamos a hacer uso de WaitGroup, el cual ayuda a contabilizar las rutinas que se tienen
              activas:
            </p>
            <pre class="prettyprint">
  package main
  import (
    "fmt"
    "log"
    "net/http"
    "os"
  )

  var wg sync.WaitGroup

  func sendRequest(url string){
    defer wg.Done() //Decrementa el contador de goroutines 
    res, err := http.Get(url)
    if err != nil{
      panic(err)
    }
    fmt.Printf("Estado: %d URL: %s\n", res.StatusCode,url)
  }
  
  func main() {
    if len(os.Args) < 2 {
      log.Fatalln("Uso: go run main.go url1 url2 .. urln")
    }
  
    for _, url := range os.Args[1:] {
      go sendRequest("https://" + url)
      wg.Add(1) //Incrementa el contador de goroutines 
    }
    wg.Wait() //Indica que toca esperar a que todas las goroutines terminen
  }
</pre>
            <p>
              Si ejecutamos de nuevo nuestro programa, vamos a ver que los resultados ahora si se muestran en consola.
            </p>
            <pre class="prettyprint">
    Estado: 200 URL: https://facebook.com
    Estado: 200 URL: https://youtube.com
    Estado: 200 URL: https://google.com
  </pre>
            <p>
              Es posible que las goroutines se mezclen en consola, debido a que pueden terminar al mismo tiempo. Dando
              como resultado:
            </p>
            <pre class="prettyprint">
    Estado: 200 URL: Estado: 200 URL: https://youtube.comhttps://facebook.com
    Estado: 200 URL: https://google.com
  </pre>
            <p>
              Para evitar que esto ocurra vamos a hacer uso de Mutex, el cual ayuda a sincronizar el acceso a recursos
              compartidos, como es el caso de la consola.
              Para hacer uso de Mutex, hacemos lo siguiente:
            </p>
            <pre class="prettyprint">
    package main
    import (
      "fmt"
      "log"
      "net/http"
      "os"
    )
  
    var wg sync.WaitGroup
    var mut sync.Mutex
  
    func sendRequest(url string){
      defer wg.Done() //Decrementa el contador de goroutines
      res, err := http.Get(url)
      if err != nil{
        panic(err)
      }
      mut.Lock()  //Bloquea el recurso inferior para que solo esta gorutine 
                  //pueda hacer uso de este
      defer mut.Unlock() //Desbloquea el recursos despues de haber terminado de usarlo
      fmt.Printf("Estado: %d URL: %s\n", res.StatusCode,url)
    }
    
    func main() {
      if len(os.Args) < 2 {
        log.Fatalln("Uso: go run main.go url1 url2 .. urln")
      }
    
      for _, url := range os.Args[1:] {
        go sendRequest("https://" + url)
        wg.Add(1) //Incrementa el contador de goroutines
      }
      wg.Wait() //Indica que toca esperar a que todas las goroutines terminen
    }
  </pre>
            <ul>
              <li>Ejemplo de concurrecia en <strong>Erlang</strong>:</li>
            </ul>
            <p>
              La función spawn en Erlang nos permiete crear un proceso en paralelo.
            </p>
            <pre class="prettyprint">
  -module(helloworld).
  -export([start/0]).
  start() ->
    Pid = spawn(fun() -> server("Hello") end),

  server(Message) ->
    io:fwrite("~p",[Message]).
</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              "Hello"
            </blockquote>

            <p>
              El operador ! nos permite enviar mensajes a los procesos.
            </p>
            <pre class="prettyprint">
  -module(helloworld).
  -export([start/0]).
  start() ->
    Pid = spawn(fun() -> server("Hello") end),
    Pid ! {hello}.

  server(Message) ->
    io:fwrite("~p",[Message]).
</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              "Hello"
            </blockquote>


            <p>
              receive permite recibir mensajes que son enviados a los procesos.
            </p>
            <pre class="prettyprint">
  -module(helloworld).
  -export([loop/0,start/0]).

  loop() ->
     receive
        {rectangle, Width, Ht} ->
           io:fwrite("Area of rectangle is ~p~n" ,[Width * Ht]),
           loop();
        {circle, R} ->
        io:fwrite("Area of circle is ~p~n" , [3.14159 * R * R]),
        loop();
     Other ->
        io:fwrite("Unknown"),
        loop()
     end.

  start() ->
     Pid = spawn(fun() -> loop() end),
     Pid ! {rectangle, 6, 10},
     Pid ! {circle, 6},
     Pid ! {square, 4, 4}.
</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              Area of rectangle is 60<br>
              Area of circle is 113.09723999999999<br>
              Unknown<br>
            </blockquote>

            <ul>
              <li>Ejemplo de concurrecia en <strong>Rust</strong>:</li>
            </ul>
            <p>
              Rust facilita la programación concurrente con las comprobaciones que se hacen en tiempo de compilación y
              con la gestión de memoria que realiza.
            </p>
            <p>
              Hilos: creamos hilos con el comando thread::spawn, que recibe un closure y se lanza justo al definirlo.
            </p>
            <pre class="prettyprint">
  use std::thread;

  fn main() {
      let child = thread::spawn(|| {
          println!("Hello from a thread!");
      });
      let _ = child.join();
  }
</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              Hello from a thread!
            </blockquote>

            <p>
              Para esperar a que un hilo termine se puede utilizar el método join.
            </p>
            <p>
              Podemos lanzar varios hilos dentro de un bucle
            </p>
            <!--<p>
  Se crea un Vec donde se meten todos los hilos para luego poder hacer un join y esperar a que todos terminen. Dentro del hilo se imprime por pantalla el índice de la iteración.
</p>-->
            <p>Aquí, en cada vuelta del bucle, iniciaremos un hilo con un iterador asociado. El primer hilo se inicia
              con el número 0, el segundo con el número 1 y así sucesivamente.
              Podemos ver en el resultado lo que se dijo antes: los subprocesos se lanzaron en un orden específico y,
              sin embargo, al mostrar los resultados, vemos que está completamente desordenado: de hecho, la velocidad
              de la ejecución de cada uno de los hilos variará.

              Si reiniciamos este programa, su salida y la visualización de los números serán diferentes; es imposible
              de predecir el orden de los números que aparecerán. Pero, si utilizamos el sistema de bloqueo y
              desbloqueo, para que cada hilo espere hasta que el anterior termine, el orden será perfecto.</p>
            <pre class="prettyprint">
  use std::thread;

  fn main() {
    let mut childs = vec![];

    for i in 0..10 {
        let child = thread::spawn(move || {
            println!("Hello from a thread! {}", i);
        });
        childs.push(child);
    }

    for c in childs {
        let _ = c.join();
    }
  }
</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              Hello from a thread! 1 <br>
              Hello from a thread! 0 <br>
              Hello from a thread! 5 <br>
              Hello from a thread! 3 <br>
              Hello from a thread! 7 <br>
              Hello from a thread! 4 <br>
              Hello from a thread! 8 <br>
              Hello from a thread! 6 <br>
              Hello from a thread! 2 <br>
              Hello from a thread! 9 <br>

            </blockquote>


            <p>
              Mutex y Arc: Para compartir una referencia a memoria entre hilos se usa Arc y Mutex en combinación.
              Arc es un contador de referencias que se puede compartir entre hilos.
              Mutex implementa el bloqueo asociado a la variable en concreto.

            </p>
            <pre class="prettyprint">
  use std::thread;
  use std::sync::{Arc, Mutex};

  fn main() {
      let mut childs = vec![];
      let shared = Arc::new(Mutex::new(String::from("")));

      for i in 0..10 {
          let s = shared.clone();
          let child = thread::spawn(move || {
              println!("In thread {}", i);

              let out = String::from("Thread ") + &i.to_string() + "\n";
              s.lock().unwrap().push_str(&out);
          });
          childs.push(child);
      }

      for c in childs {
          let _ = c.join();
      }

      println!("\nOutput:\n{}", *(shared.lock().unwrap()));
  }

</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              In thread 0 <br>
              In thread 3 <br>
              In thread 5 <br>
              In thread 4 <br>
              In thread 2 <br>
              In thread 6 <br>
              In thread 7 <br>
              In thread 8 <br>
              In thread 1 <br>
              In thread 9 <br>
              <br>
              Output: <br>
              Thread 0 <br>
              Thread 3 <br>
              Thread 5 <br>
              Thread 4 <br>
              Thread 2 <br>
              Thread 6 <br>
              Thread 7 <br>
              Thread 8 <br>
              Thread 1 <br>
              Thread 9 <br>
            </blockquote>

            <p>
              En este ejemplo se define la cadena dentro de un Mutex y este dentro de un Arc, así se comparte la memoria
              entre hilos.
              <br>
              channel crea un transmisor, tx, y un receptor, rx, en cada hilo, clona el transmisor y escribe en este la
              salida. En el send se puede enviar cualquier tipo de dato según se cree el channel, no se pueden enviar
              diferentes tipos de datos por el mismo canal.

            </p>
            <pre class="prettyprint">
  use std::thread;
  use std::sync::mpsc;

  fn main() {
      let (tx, rx) = mpsc::channel();
      let mut childs = vec![];

      for i in 0..10 {
          let tx = tx.clone();
          let child = thread::spawn(move || {
              println!("In thread {}", i);

              let out = String::from("Thread ") + &i.to_string();
              tx.send(out).unwrap();
          });
          childs.push(child);
      }

      for c in childs {
          let _ = c.join();
      }

      println!("\nOutput:");
      loop {
          match rx.try_recv() {
              Ok(x) => println!("{}", x),
              Err(_) => break
          }
      }
  }

</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              In thread 0 <br>
              In thread 2 <br>
              In thread 1 <br>
              In thread 4 <br>
              In thread 5 <br>
              In thread 6 <br>
              In thread 3 <br>
              In thread 8 <br>
              In thread 7 <br>
              In thread 9 <br>
              <br>
              Output: <br>
              Thread 0 <br>
              Thread 2 <br>
              Thread 1 <br>
              Thread 4 <br>
              Thread 5 <br>
              Thread 6 <br>
              Thread 8 <br>
              Thread 7 <br>
              Thread 9 <br>
              Thread 3 <br>
            </blockquote>

            <ul>
              <li>Ejemplo de concurrencia en <strong>Crystal</strong>:</li>
            </ul>
            <p>
              Crystal usa hilos llamados fibras para lograr concurrencia. Las fibras se comunican entre sí mediante
              canales, como en Go o Clojure, sin tener que recurrir a la memoria compartida o bloqueos.
              <br>
              Cuando se inicia un programa, se activa la fibra principal que ejecutará su código de nivel superior.
              Allí, uno puede engendrar (spawn) más fibras.
              Los componentes de un programa son:
            <ul>
              <li>Runtime Scheduler, a cargo de ejecutar todas las fibras cuando sea el momento adecuado. </li>
              <li>El bucle de eventos, que es solo otra fibra, está a cargo de tareas asíncronas, como por ejemplo
                archivos, sockets, pipes, señales y temporizadores.</li>
              <li>Canales, para comunicar datos entre fibras. Runtime Scheduler coordinará fibras y canales para su
                comunicación.</li>
              <li>Garbage collector: para limpiar la memoria que "ya no se usa".</li>
            </ul>
            Fibras: Para generar una fibra se usa el comando spawn
            </p>

            <pre class="prettyprint">
  spawn do
    loop do
      puts "Hello!"
    end
  end

  sleep 1.second
</pre>
            <p>
              Este programa imprimirá "¡Hello!" por un segundo y luego saldrá. Esto se debe a que la llamada de espera
              programará la fibra principal que se ejecutará en un segundo y luego ejecutará otra fibra "lista para
              ejecutarse", que en este caso es la de arriba.
              <br><br>
              Otra manera seria:
            </p>

            <pre class="prettyprint">
  spawn do
    loop do
      puts "Hello!"
    end
  end

  Fiber.yield
</pre>

            <p>
              Fiber.yield le dirá al scheduler que ejecute la otra fibra. Esto imprimirá "Hello" hasta los bloques de
              salida estándar y luego la ejecución continuará con la fibra principal y el programa saldrá.
            </p>

            <p>
              Creando(spawn) una llamada:
              <br><br>
              El programa imprime los números del 0 al 9. Se crea un Proc y se invoca pasando I, por lo que el valor se
              copia y la fibra engendrada recibe una copia.
            </p>

            <pre class="prettyprint">
  i = 0
  while i < 10
    proc = ->(x : Int32) do
      spawn do
        puts(x)
      end
    end
    proc.call(i)
    i += 1
  end

  Fiber.yield
</pre>

            <p>
              La salida es la siguiente:
            </p>

            <blockquote>
              0 <br>
              1 <br>
              2 <br>
              3 <br>
              4 <br>
              5 <br>
              6 <br>
              7 <br>
              8 <br>
              9 <br>
            </blockquote>

            <p>
              Canales:
              <br>
              Cuando el programa ejecuta una recepción, esa fibra se bloquea y la ejecución continúa con la otra fibra.
              Cuando se ejecuta un envió, la ejecución continúa con la fibra que estaba esperando en ese canal.
            </p>

            <pre class="prettyprint">
  channel = Channel(Int32).new

  spawn do
    puts "Before first send"
    channel.send(1)
    puts "Before second send"
    channel.send(2)
  end

  puts "Before first receive"
  value = channel.receive
  puts value # => 1

  puts "Before second receive"
  value = channel.receive
  puts value # => 2
</pre>
            <p>
              La salida es la siguiente:
            </p>
            <blockquote>
              Before first receive <br>
              Before first send <br>
              1 <br>
              Before second receive <br>
              Before second send <br>
              2 <br>

            </blockquote>

            <ul>
              <li>Ejemplo en <strong>C</strong> con el juego de pacman:<br />
                Aquí, el programa debe poder recibir la entrada teclado del usuario. Pero también, al mismo tiempo,
                tienes que:
                <br />
                - Calcula los movimientos de los enemigos gracias a la inteligencia artificial.<br />
                - Ver los diferentes desplazamientos.<br />
                - Actualizar el mapa<br />
              </li>
            </ul>

            <div class="highlight highlight-source-python">
              <pre>
<span class="pl-k">int</span> <span class="pl-en">main_loop</span>(<span class="pl-smi">IGame *Game, IGui *curse</span>):
  {
    <span class="pl-k">board</span> game;
    <span class="pl-k">t_orientation</span> dir;
    <span class="pl-k">int</span> k = 0;

    <span class="pl-s">while</span> (k == 0)
    {
      dir = curse-><span class="pl-c1">get_touch</span>();
      <span class="pl-s">if</span> (dir > 4)
        <span class="pl-c1">return</span> (dir);
      k = Game-><span class="pl-c1">check_move</span>(dir);
      game = Game-><span class="pl-c1">get_board</span>();
      <span class="pl-s">if</span> (curse-><span class="pl-c1">display</span>(game) == -1)
        <span class="pl-c1">return</span> (0);
    }
    <span class="pl-c1">delete</span> curse;
    <span class="pl-c1">delete</span> Game;
    <span class="pl-c1">return</span> (0);
  }
</pre>
            </div>

            <p>Si observamos el código que se muestra, la función get_touch iniciará un hilo que se ocupará de recuperar
              la entrada del teclado pero no bloqueará el resto del programa: no esperará a recuperar una tecla para
              continuar.</p>

            <img src="images/Pacman.gif"><br /><br /><br />


          </div>

          <h1>
            <a id="presentacion" class="anchor" aria-hidden="true"><span aria-hidden="true"
                class="octicon octicon-link"></span></a>Presentación
          </h1>
          <a href="https://drive.google.com/open?id=0B_B-BoNU4ZaIOTNrUWlWXzBjNmc">Enlace</a>
          <br>
          <a
            href="https://docs.google.com/a/unal.edu.co/presentation/d/1qwH2qt_KMMoaIlgN5xVuBpEylf9bC_TNVD3nE5foKBo/edit?usp=sharing">Enlace
            2</a>
          <br>
          <a
            href="https://docs.google.com/presentation/d/1q_2wpfu53nHfQR1IbmdUpXmySJa0J-8b_C6rLYsoe54/edit?usp=sharing">Enlace
            3
          </a>
          <br>
          <a
            href="https://docs.google.com/presentation/d/17fNIbIREBY8tKs3orhIl18sEO1qxzxMrLisaH3QjIAY/edit?usp=sharing">Enlace
            4
          </a>
          <h1>
            <a id="taller" class="anchor" aria-hidden="true"><span aria-hidden="true"
                class="octicon octicon-link"></span></a>Taller
          </h1>
          <a href="https://drive.google.com/open?id=0B_B-BoNU4ZaIcEZQX2ttZU1mVFk">Enlace</a>
          <br>
          <a
            href="https://docs.google.com/a/unal.edu.co/document/d/1wLW-AtC3ap86P4z547Tqse0R3X7bGChVAk6QHdkfu4E/edit?usp=sharing">Enlace
            2</a>


            


          <div id="referencias">
            <br><br>

            <h1>
              <a class="anchor" href="#referencias" aria-hidden="true"><span aria-hidden="true"
                  class="octicon octicon-link"></span></a>Referencias
            </h1>

            <ul>
              <li style="background-color: #FFFFFF;"><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://go-tour-es.appspot.com/#1">https://go-tour-es.appspot.com/#1</a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://geekytheory.com/concurrencia-en-javascript/">https://geekytheory.com/concurrencia-en-javascript/</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www.ctr.unican.es/asignaturas/procodis_3_ii/doc/procodis_3_01.pdf">http://www.ctr.unican.es/asignaturas/procodis_3_ii/doc/procodis_3_01.pdf</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www.genbetadev.com/python/multiprocesamiento-en-python-threads-a-fondo-introduccion">http://www.genbetadev.com/python/multiprocesamiento-en-python-threads-a-fondo-introduccion</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www.ctr.unican.es/asignaturas/procodis_3_ii/doc/procodis_1_01.pdf">http://www.ctr.unican.es/asignaturas/procodis_3_ii/doc/procodis_1_01.pdf</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-multicore-programming-primer-january-iap-2007/lecture-notes-and-video/l4-introduction-to-concurrent-programming/">http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-multicore-programming-primer-january-iap-2007/lecture-notes-and-video/l4-introduction-to-concurrent-programming/</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://sites.google.com/a/unal.edu.co/sistemas-operativos/">https://sites.google.com/a/unal.edu.co/sistemas-operativos/</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://www.fing.edu.uy/tecnoinf/mvd/cursos/so/material/teo/so07-concurrencia.pdf">https://www.fing.edu.uy/tecnoinf/mvd/cursos/so/material/teo/so07-concurrencia.pdf</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www2.ulpgc.es/hege/almacen/download/20/20233/tema1.pdf">http://www2.ulpgc.es/hege/almacen/download/20/20233/tema1.pdf</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://concurrencia-go.appspot.com/">http://concurrencia-go.appspot.com/</a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://buguroo.com/es/concurrencia-real-en-python">https://buguroo.com/es/concurrencia-real-en-python</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www.noesispoint.com/jsp/scjp/SCJPch12.htm">http://www.noesispoint.com/jsp/scjp/SCJPch12.htm</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www.javaworld.com/article/2076774/java-concurrency/programming-java-threads-in-the-real-world--part-1.html">http://www.javaworld.com/article/2076774/java-concurrency/programming-java-threads-in-the-real-world--part-1.html</a>
              </li>
              <li>Abraham Silberschatz-Operating System Concepts (9th,2012.12)</li>
              <li>Abraham Silberschatz-Operating System Concepts Essentials (2nd,2013)</li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="http://wiki.inf.utfsm.cl/index.php?title=Monitores#.C2.BFQu.C3.A9_son_los_Monitores.3F
">http://wiki.inf.utfsm.cl/index.php?title=Monitores#.C2.BFQu.C3.A9_son_los_Monitores.3F
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://1984.lsi.us.es/wiki-ssoo/index.php/Mensajería">http://1984.lsi.us.es/wiki-ssoo/index.php/Mensajería
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://sistop.gwolf.org/html/03_planificacion_de_procesos.html#sec-1">http://sistop.gwolf.org/html/03_planificacion_de_procesos.html#sec-1</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://es.wikipedia.org/wiki/Problema_productor-consumidor">https://es.wikipedia.org/wiki/Problema_productor-consumidor</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="https://www.slant.co/topics/6024/~programming-languages-for-concurrent-programming
">https://www.slant.co/topics/6024/~programming-languages-for-concurrent-programming
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://blanchardspace.wordpress.com/2016/08/19/rust-lenguaje/">https://blanchardspace.wordpress.com/2016/08/19/rust-lenguaje/</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="https://www.genbetadev.com/frameworks/elixir
">https://www.genbetadev.com/frameworks/elixir
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="https://www.genbetadev.com/frameworks/elixir
">https://www.genbetadev.com/frameworks/elixir
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="https://www.ecured.cu/Lenguaje_de_programaci%C3%B3n_Go
">https://www.ecured.cu/Lenguaje_de_programaci%C3%B3n_Go
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="https://wiki.haskell.org/Es/Introduccion
">https://wiki.haskell.org/Es/Introduccion
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://g3ortega.com/programming_languages/2016/06/10/crystal-lenguaje-de-programacion-el-por-que-y-el-como.html">http://g3ortega.com/programming_languages/2016/06/10/crystal-lenguaje-de-programacion-el-por-que-y-el-como.html</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="https://en.wikipedia.org/wiki/Crystal_(programming_language)
">https://en.wikipedia.org/wiki/Crystal_(programming_language)
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://www.tutorialspoint.com/erlang/erlang_concurrency.htm">https://www.tutorialspoint.com/erlang/erlang_concurrency.htm</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;" href="http://concurrencia-go.appspot.com/
">http://concurrencia-go.appspot.com/
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://www.ctr.unican.es/asignaturas/procodis_3_II/Doc/Procodis_1_01.pdf">Programación
                  concurrente - J.M. Drake </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://pegasus.javeriana.edu.co/~scada/concurrencia.html">http://pegasus.javeriana.edu.co/~scada/concurrencia.html
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://babel.upm.es/teaching/concurrencia/material/slides/groman/CC_CondCarrera.pdf">Condición
                  de Carrera </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://takuti.me/note/parallel-vs-concurrent/">Parallel programming vs. Concurrent Programming
                </a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1107&context=sei">Concepts of concurrent
                  programming</a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://books.google.com.co/books?id=k1cIQwg23vAC&pg=PA10&lpg=PA11&dq=Concurrent+computing+history&source=bl&ots=CqOM6TbQ8e&sig=A16KtMDjujSMg34iVx7RPnLE3tc&hl=es-419&sa=X&ved=2ahUKEwjA1JrumonfAhWNm1kKHfPFANUQ6AEwCHoECAkQAQ#v=onepage&q=Concurrent%20computing%20history&f=false">Historia
                  Computacion concurrente</a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://books.google.com.co/books?id=JeT9wlXhUTMC&pg=PA92&dq=Shortest+Process+next+(SPN)&hl=es-419&sa=X&ved=0ahUKEwjUzu2jpYnfAhXLq1kKHUcKAFoQ6AEILDAA#v=onepage&q=Shortest%20Process%20next%20(SPN)&f=false">Principles
                  of Modern Operating Systems</a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://www.oscarblancarteblog.com/2017/03/29/concurrencia-vs-paralelismo/">Concurrencia vs
                  Paralelismo</a></li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://webprogramacion.com/44/sistemas-operativos/exclusion-mutua.aspx">Paso de mensajes</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://www.youtube.com/watch?v=3atNYmqXyV4">Ejemplo Go Concurrencia</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://www.dlsi.ua.es/asignaturas/pc/teoria/t01.pdf">Conceptos fundamentales Programación
                  Concurrente</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://www.researchgate.net/publication/268289930_Programacion_concurrente">Programación
                  concurrente</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  href="https://platzi.com/clases/1984-servidores-rust/35177-creacion-de-hilos-con-rust/">Creación de
                  hilos con Rust</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://aws.amazon.com/es/blogs/compute/managing-aws-lambda-function-concurrency/">Managing AWS Lambda Function Concurrency | AWS Compute Blog</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://es.acervolima.com/multithreading-en-python-conjunto-2sincronizacion/">Multithreading en Python | Conjunto 2(sincronización)</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://www.amazon.com/Rust-Programming-Example-concurrent-applications/dp/1788390636">Rust Programming By Example: Enter the world of Rust by building engaging, concurrent, reactive, and robust applications</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://cs.lmu.edu/~ray/notes/introconcurrency/">Introduction to Concurrency</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://ericnormand.me/article/concurrency-vs-parallelism">Concurrency and Parallelism in the Real World</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://www.quora.com/What-is-concurrency-and-why-is-it-used-in-programming">What is concurrency used for?</a>
              </li> 
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://www.geeksforgeeks.org/concurrency-in-operating-system/">Concurrency in operating system</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                  >Python in a Nutshell</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                >Concurrent Programming: The Java Programming Language - Stephen Hartley y Paul Tymann</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                >Concurrent Programming in Java: Design Principles and Patterns - Doug Lea </a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://arxiv.org/ftp/arxiv/papers/1008/1008.1459.pdf">Actor Model of Computation: Scalable Robust Information Systems</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://deadlockempire.github.io/">Aprende Concurrencia matando dragones</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://archive.org/details/softwareengineer0002booc">Software Engineering with Ada</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://medium.com/aviabird/10-amazing-open-source-elixir-phoenix-apps-e2c52ee25053">10 Amazing open source Elixir/Phoenix Apps</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://www.mycplus.com/featured-articles/source-game-development-engine/">Source Game Development Engine</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://towardsdatascience.com/top-16-python-applications-in-real-world-a0404111ac23">Top 16 Python Applications in Real-World</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://crystal-lang.org/used_in_prod/">Crystal: Used in production</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://serokell.io/blog/top-software-written-in-haskell">11 Companies That Use Haskell in Production</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://www.linkedin.com/pulse/3-best-apps-made-golang-codalien/">3 best apps made with Golang</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://codesync.global/media/successful-companies-using-elixir-and-erlang/">Successful Companies Use Erlang and Elixir</a>
              </li>
              <li><a style="background-color: #FFFFFF;color: blue; text-align: left;"
                href="https://www.theregister.com/2022/10/05/rust_kernel_pull_request_pulled/">Linux 6.1: Rust to hit mainline kernel</a>
              </li>
            </ul>
          </div>

        </div>
        <div id="Integrantes">
          <br><br>

          <h1>
            <a class="anchor" href="#Integrantes" aria-hidden="true"><span aria-hidden="true"
                class="octicon octicon-link"></span></a>Integrantes
          </h1>

          <ul>
            <li>Carlos Julián Cordero Guevara</li>
            <li>Cristian Alejandro Chávez Becerra</li>
            <li>Jorge Alberto Rodríguez Corredor</li>
            <li>Manuel David Medrano Monroy</li>
            <li>Bryam Diaz</li>
            <li>Santiago Marquez</li>
            <li>Christian Vaca</li>
            <li>Kevin Mendez Paez</li>
            <li>Diego Alejandro Guevara Rocha</li>
            <li>Jhon Emmanuel Torres</li>
            <li>Raul Ramirez Penagos</li>
            <li>Diego Rodriguez</li>
            <li>Fabian David Conejo</li>
            <li>Milder Hernandez</li>
            <li>Diego Felipe Rodriguez Chaparro</li>
            <li>Nicolas Ricardo Enciso</li>
            <li>Camilo Alfonso Mosquera Benavides</li>
            <li>Juan Sebastián Herrera Maldonado </li>
            <li>Florent Sebag</li>
            <li>Karen Ximena Combita Alfonso</li>
            <li>Michael Tomas Velasquez Gordillo</li>
            <li>Cristian David Martinez Collazos</li>
            <li>Alejandro Sebastián Alejo Patarroyo</li>
            <li>Laura Vanessa Bohórquez Ramirez</li>
            <li>Johan Sebastian Salamanca Gonzalez</li>
            <li>Mauricio Mesa Burbano</li>
            <li>Cesar Augusto Torres Ardila</li>
            <li>Nicolas Mateo Casas Ramos</li>
            <li>Marcelo Escamilla Sanchez</li>
            <li>Ivan Delgado Gonzalez</li>
            <li>David Santiago Fajardo Barrera</li>
            <li>Juan Camilo Acosta Rojas</li>
            <li>Cristian Santiago Vargas Ortiz</li>
            <li>Juan Esteban Rozo Urbina</li>
            <li>Camilo Andres Carranza Carvajal</li>
            <li>Julio Javier Muñoz</li>
            <li>Elkin Mauricio Mendez</li>
            <li>Santiago Morales Pulido</li>
            <li>Catalina Aldana Mongui</li>
            <li>Santiago Hernandez Montaño</li>
            <li>Cristian Camilo Garcia Barrera</li>
            <li>Diego Armando Velasquez Vargas</li>
            <li>Daniel Santiago Gaitán</li>
            <li>Carlos Andres Rios Rojas</li>
            <li>Juan Sebastian Peñafiel Ojeda</li>
            <li>Diego Efrain Mojica Mendez</li>
            <li>Juliana Cardozo Pedraza</li>
            <li>Santiago Mondragón Gómez</li>
          </ul>
        </div>
      </section>

      <aside id="sidebar">
        <a href="https://github.com/ferestrepoca/paradigmas-de-programacion/archive/gh-pages.zip" class="button">
          <small>Download</small>
          .zip file
        </a>
        <a href="https://github.com/ferestrepoca/paradigmas-de-programacion/archive/gh-pages.tar.gz" class="button">
          <small>Download</small>
          .tar.gz file
        </a>

        <p class="repo-owner"><a href="http://ferestrepoca.github.io/paradigmas-de-programacion/"></a> is maintained by
          <a href="http://dis.unal.edu.co/~ferestrepoca/">Felipe Restrepo.</a>
        </p>

        <p>This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the Architect theme by
          <a href="https://twitter.com/jasonlong">Jason Long</a>.
        </p>
      </aside>
    </div>
  </div>

  <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
    integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx"
    crossorigin="anonymous"></script>
</body>

</html>
